---
title: "08: Analysis"
---

## Overview

This tutorial is a speedrun of how to run and report a variety of analyses that are commonly used for undergraduate dissertation projects at the University of Sussex, based on a survey of supervisors in summer 2023.

::: callout-important
**This is not a statistics tutorial**, so interpretation of the following models will be only cursory. For a complete explanation of the statistical concepts and interpretation, refer to the {discovr} tutorials that correspond to the following sections:

-   Categorical Predictors
    -   Comparing Several Means (One-Way ANOVA): `discovr_11`
    -   Factorical Designs: `discovr_13`
    -   Mixed Designs: `discovr_16`
-   Moderation: `discovr_10`
-   Mediation: `discovr_10`
:::

::: {.callout-tip title="Using the {discovr} tutorials" collapse="true"}
[Prof Andy Field's {discovr} tutorials](https://github.com/profandyfield/discovr) provide detailed walkthroughs of both the R code and the statistical concepts of a variety of statistical analyses. They are a good place to look first to understand what your UG supervisees or advisees have been taught on a particular topic.

To install the tutorials, run the following **in the Console**. Note that this is **not necessary** for the live workshop Cloud workspaces, which already have the tutorials installed.

``` r
if(!require(remotes)){
  install.packages('remotes')
}

remotes::install_github("profandyfield/discovr")
```

The {discovr} tutorials are built in {learnr}, an interactive platform for learning and running R code. So, unlike the tutorial you're currently reading, they must be run inside an R session.

To start a tutorial, open any project and click on the Tutorial tab in the Environment pane. Scroll down to the tutorial you want and click the "Start Tutorial ▶️" button to load the tutorial.

Because {discovr} tutorials run within R, you don't need to use any external documents; you can write and run R code within the tutorial itself. However, I *strongly* recommend that whenever you work with these tutorials, you write and run your code in a separate document, otherwise you will have no record of the code and output.
:::

## Setup

### Packages

There are a *lot* of packages that we will make our way through today.

::: {.callout-note appearance="minimal" title="Exercise"}
Load the {tidyverse} packages.

::: {.callout-note collapse="true" title="Solution"}
```{r}
library(tidyverse)

```
:::
:::

### Data

Today we're continuing to work with the dataset courtesy of fantastic Sussex colleague [Jenny Terry](https://www.jennyterry.co.uk/). This dataset contains real data about statistics and maths anxiety. For these latter two tutorials, I've created averaged scores for each overall scale and subscale, and dropped the individual items.

::: {.callout-note appearance="minimal" title="Exercise"}
Read in the dataset and save it in a new object, `anx_score_data`.

On the Cloud, you can read in this dataset from the `data` folder using `here::here()`.

Elsewhere, you can download the dataset, or copy the dataset URL, from the [Data and Workbooks page](../../../data_workbooks.qmd).

::: {.callout-note collapse="true" title="Solution"}
Read in from file:

```{r}
anx_scores_data <- readr::read_csv(here::here("data/anx_scores_data.csv"))
```

Read in from URL:

```{r}
#| eval: false

anx_scores_data <- readr::read_csv("https://raw.githubusercontent.com/drmankin/practicum/master/data/anx_scores_data.csv")
```
:::
:::

#### Codebook

There's quite a bit in this dataset, so you will need to refer to the codebook below for a description of all the variables.

::: {.callout-tip title="Dataset Info Recap" collapse="true"}
This study explored the difference between maths and statistics anxiety, widely assumed to be different constructs. Participants completed the Statistics Anxiety Rating Scale ([STARS](https://explore.bps.org.uk/content/bpsptr/24/2/101)) and Maths Anxiety Rating Scale - Revised ([R-MARS](https://journals.sagepub.com/doi/10.1177/001316448204200218)), as well as modified versions, the STARS-M and R-MARS-S. In the modified versions of the scales, references to statistics and maths were swapped; for example, the STARS item "Studying for an examination in a statistics course" became the STARS-M item "Studying for an examination in a maths course"; and the R-MARS item "Walking into a maths class" because the R-MARS-S item "Walking into a statistics class".

Participants also completed the State-Trait Inventory for Cognitive and Somatic Anxiety ([STICSA](https://www.cambridge.org/core/journals/behavioural-and-cognitive-psychotherapy/article/abs/distinguishing-cognitive-and-somatic-dimensions-of-state-and-trait-anxiety-development-and-validation-of-the-statetrait-inventory-for-cognitive-and-somatic-anxiety-sticsa/78FDDC5BCDE9D4164434AC10E83DCEF3?utm_campaign=shareaholic&utm_medium=copy_link&utm_source=bookmark)). They completed the state anxiety items twice: once before, and once after, answering a set of five MCQ questions. These MCQ questions were either about maths, or about statistics; each participant only saw one of the two MCQ conditions.
:::

::: callout-important
For learning purposes, I've randomly generated some additional variables to add to the dataset containing info on distribution channel, consent, gender, and age. Especially for the consent variable, don't worry: all the participants in this dataset did consent to the original study. I've simulated and added this variable in later to practice removing participants.
:::

```{r}
#| echo: false

readr::read_csv(here::here("data/anx_scores_codebook.csv")) %>%
  kableExtra::kbl(
    col.names = stringr::str_to_title(names(.)),
    html = TRUE
  ) |> 
  kableExtra::kable_styling()
```

If you have some experience with R, you are welcome to instead use another dataset that you are familiar with or are keen to explore. However, remember that anything you upload to Posit Cloud is visible to all workspace admins, so keep GDPR in mind.

## Categorical Predictors

We'll begin by looking at several examples of models with categorical predictors. Traditionally, these are all different types of "ANOVA" (ANalysis Of VAriance), but research methods teaching at Sussex teaches all of these models in the framework of the general linear model.

### Comparing Several Means

Our first model will be linear model with a categorical predictor with more than two categories - traditionally a "one-way independent ANOVA". For our practice today, we'll look at the differences in the STARS Asking for Help subscore by gender.

::: callout-tip
This section is derived from `discovr_11`, which also has more explanations and advanced techniques.
:::

#### Plot

Let's start by visualising our variables. The `discovr` tutorial also includes code for a table of means and CIs, which we won't cover here.

::: {.callout-note appearance="minimal" title="Exercise"}
Use what we covered in the last tutorial to create a violin plot with means and CIs. **Optionally**, spruce up your plot with labels and a theme.

::: {.callout-note collapse="true" title="Solution"}
```{r}
anx_scores_data |> 
  ggplot2::ggplot(aes(x = gender, y = stars_help_score)) + 
  geom_violin() +
  stat_summary(fun.data = "mean_cl_boot") +
  ## here's the sprucing
  labs(x = "Gender Identity", y = "Mean Trait Anxiety") +
  theme_minimal()
```
:::
:::

#### Fit the Model

As mentioned above, this model is taught as a linear model with a categorical predictor. That's literal: we're going to use the `lm()` function to fit the model. It was a bit ago, but we covered the linear model and `lm()` function in more depth back in [Tutorial 04](../01_fundRmentals/04_lm.qmd).

Unfortunately, we'll need to make a quick change to our data beforehand.

::: {.callout-note appearance="minimal" title="Exercise"}

Change out the "/" in the value `other/pnts` for an underscore, so the value reads `other_pnts`.

*Hint*: You can try `stringr::str_replace_all()` for a {tidyverse} solution, or if you're basic like me, have a look at `gsub()`.

::: {.callout-note collapse="true" title="Solution"}

{stringr} solution:

```{r}
anx_scores_data <- anx_scores_data |> 
  dplyr::mutate(
    gender = stringr::str_replace_all(gender, 
                                      pattern = "/", 
                                      replacement = "_")
  )
```

`gsub()` solution:

```{r}
#| eval: false

anx_scores_data <- anx_scores_data |> 
  dplyr::mutate(
    gender = gsub("/", "_", gender)
  )
```

These will do exactly the same thing, so which one you use is completely preference. It's very useful to know how to do this sort of thing though!
:::
:::

::: {.callout-note appearance="minimal" title="Exercise"}
Fit a linear model with STARS Asking for Help subscale score as the outcome, and gender as the predictor, and save this model as `stars_lm`.

Then, obtain the *F*-ratio for this model. Does the overall model explain the variance in the outcome better than just using the overall mean of the outcome? **Optionally**, use the `discovr` tutorial to get an overall effect size as well.

Finally, get a table of model parameters, including confidence intervals, using `broom::tidy()`. **Optionally**, print it out in a nice APA-style table.

::: {.callout-note collapse="true" title="Solution"}
First, let's fit the model and store it in `stars_lm`.

```{r}
stars_lm <- lm(stars_help_score ~ gender, data = anx_scores_data)

```

We saw previously that we can get R^2^ and *F* for the model using `broom::glance()`:

```{r}
broom::glance(stars_lm)
```

In `discovr_11`, though, we see that we can use the `anova()` function as well. We used this previously to compare models, but given only one model, it will instead compare that model to the null model (i.e. the mean of the outcome). The tutorial also provides code to get an omega effect size.

```{r}
anova(stars_lm) |> 
  parameters::model_parameters(effectsize_type = "omega")
```

Finally, we can get the parameters table as a dataset, or format it nicely with {papaja}.

```{r}
## Raw output
broom::tidy(stars_lm, conf.int = TRUE)

## Papaja table
papaja::apa_table(papaja::apa_print(stars_lm)$table)
```
:::
:::

```{r}
#| include: false

str_to_oxford <- function(x, backticks = TRUE){
  if(backticks){
    x <- paste0("`", x, "`")
  }
  
  x |> 
    paste0(collapse = ", ") |> 
    sub(pattern = ", ([^,]*)$", replacement = ", and \\1")
}

gender_oxford <- anx_scores_data |> 
  dplyr::pull(gender) |> 
  unique() |> 
  str_to_oxford()

params_oxford <- broom::tidy(stars_lm, conf.int = TRUE) |> 
  dplyr::slice(-1) |> 
  dplyr::pull(term) |> 
  str_to_oxford(backticks = TRUE)
  
```

To read this output, we need to know a few things about how R deals with categorical predictors by default.

Unless we specify comparisons/contracts, `lm()` will by default fit a model with the first category as the baseline. What do we mean by the "first"? Here, the first alphabetically. Our categories were `r gender_oxford`, so the first is "female". (You can see in the plot as well that the categories have been automatically ordered this way.) This means that **the intercept represents the mean of the outcome in the baseline group** - here, the mean Asking for Help anxiety score in female participants.

The three other three parameter estimates - `r params_oxford` - each represent the **difference in the mean of the outcome** between the baseline category and each other category. For example, the *b* estimate and the rest of the statistics on the `gendermale` row represent the difference in mean Asking for Help anxiety between female and male participants. The next, `gendernon-binary`, represents the difference in mean Asking for Help anxiety between female and non-binary participants, and so on.

#### Contrasts

When they cover this week in second year, UGs are taught to manually write orthogonal contrast weights. We are *not* going to do that but the whole process is described in the {discovr} tutorial if that's something you want to do.

Instead, we're going to use built-in contrasts. The structure generally looks like this:

``` r
contrasts(dataset_name$variable_name) <- contr.*(...)
```

On the left side of this statement, we're using the `contrasts()` function to set the contrasts for a particular variable. Notice this is the variable *in the dataset*, which we're specifying using `$` notation as we've seen before. To do this, we assign a pre-set series of contrasts using one of the `contr.*()` family of functions. Here, the `*` represents one of a few options, such as `contr.sum()` (the one we'll use now), `contr.helmert()`, etc., and the `...` represents some more arguments you may need to add to this function, depending on which one you want. You can get information about all of them by pulling up the help documentation on any of them.

For now, we're going to use `contr.sum()`, which requires that we also provide the number of levels (here, four: `r gender_oxford`). There's a catch, though - we can only set contrasts for *factors*, so we'll first need to do something about the `gender` variable.

::: {.callout-note appearance="minimal" title="Exercise"}
First, change the character `gender` variable into a factor. You can do this just for this variable, or **optionally** use some of the challenge functions from the last tutorials to change all of the character variables into factors together.

Then, use `contr.sum()` to set the contrasts for the `gender` variable.

::: {.callout-note collapse="true" title="Solution"}
Without any fancy extras, we can just change `gender` into a factor directly - don't forget to assign the change back to the dataset.

```{r}
#| eval: false
anx_scores_data <- anx_scores_data |> 
  dplyr::mutate(
    gender = factor(gender)
  )
```

To make sure we don't have to deal with this again, we can change all of the character variables into factors with the `across()` + `where()` tag team from the last tutorial.

```{r}
anx_scores_data <- anx_scores_data |> 
  dplyr::mutate(
    across(where(is.character), factor)
  )
```

Now that `gender` is a factor, we can set the contrasts.

```{r}
contrasts(anx_scores_data$gender) <- contr.sum(4)
```
:::
:::

::: {.callout-note appearance="minimal" title="Exercise"}
Fit the model again and get the same parameters table as before.

::: {.callout-note collapse="true" title="Solution"}
Because the underlying `gender` variable has changed, all we need to do is rerun the *exact same code* as before, which will now produce output with contrasts.

Just so I can compare them if I want to, I'm going to call this model something different.

```{r}
stars_contr_lm <- lm(stars_help_score ~ gender, data = anx_scores_data)

papaja::apa_table(papaja::apa_print(stars_contr_lm)$table)
```
:::
:::

#### Post-Hoc Tests

If we didn't have an *a priori* prediction about the differences between groups, we may decide to instead run post-hoc tests. 

::: {.callout-note appearance="minimal" title="Exercise"}
Use the function `modelbased::estimate_contrasts()` to get post-hoc tests by putting in the original model

::: {.callout-note collapse="true" title="Solution"}
```{r}
anx_scores_data |> 
  dplyr::group_by(gender) |> 
  dplyr::summarise(
    n = dplyr::n()
  )



modelbased::estimate_contrasts(stars_lm, 
                               contrast = "gender")
```
:::
:::

### Factorial Designs

Our next analysis will be factorial design with two categorical predicts, traditionally called a 2x2 independent ANOVA. Although this can certainly be done using `lm()`, at this point the `lm()` route becomes a bit burdensome, so we will instead switch to using the {afex} package, which is designed especially for these types of analyses ("afex" stands for "analysis of factorial experiments"). The {discovr} tutorials for this and subsequent similar ANOVA-type analyses demonstrate both {afex} and `lm()` options, but students are only required to use {afex}.

For our practice today, we'll look at again at gender, but this time with male and female participants only, and we'll compare whether their post-MCQ state anxiety scores are different depending on whether they saw stats or maths MCQ questions.

::: callout-tip
This section is derived from `discovr_13`, which also has more explanations and advanced techniques.
:::

#### Fit the Model

```{r}
anx_scores_data <- anx_scores_data |> 
  dplyr::filter(gender %in% c("male", "female")) |> 
  dplyr::mutate(
    sticsa_cat = ifelse(sticsa_trait_score > 2, "high", "low")
  )
```

```{r}
# fit the model:
mcq_afx <- afex::aov_4(sticsa_post_state_score ~ mcq*sticsa_cat + (1|id), 
                       data = anx_scores_data)
mcq_afx #this shows us the model
```

#### Interaction Plot

Besides producing easy-to-read output, one of the handy things about {afex} is that you can quickly generate factorial interaction plots. The `afex_plot()` function lets you take a model you've produced with {afex} and visualise it easily. Since we have one of those to hand (convenient!) let's have a look.

Minimally, we need to provide the model object, the variable to put on the *x*-axis, and the "trace", the variable on separate lines. Unlike with {ggplot}, though, here we need to provide the names of those variables as strings inside quotes.

```{r}
afex::afex_plot(mcq_afx,
                x = "mcq",
                trace = "sticsa_cat")
```

The plot we get for very little work already has a lot of useful stuff. We get means for each combination of groups, with different values on the "trace" variable with different point shapes and connected by different lines. It needs some work, of course, but especially as a quick glimpse at the relationships of interest, it's a good start!

::: {.callout-note appearance="minimal" title="Exercise"}

**CHALLENGE**: Use the `afex_plot()` help documentation and last week's tutorial on {ggplot2} to clean up this plot and make it presentable.

::: {.callout-note collapse="true" title="Solution"}

Here's what I went for!

```{r}

afex::afex_plot(mcq_afx, "mcq", "sticsa_cat",
                legend_title = "STICSA Trait\nAnxiety",
                factor_levels = list(
                  sticsa_cat = c(high = "High",
                                 low = "Low")),
                data_arg = list(
                  position = position_jitterdodge()
                )
                ) +
  scale_x_discrete(name = "Type of MCQ", 
                     labels = c("Maths", "Stats")) +
  scale_y_continuous(name = "STICSA Post-Test State Anxiety",
                     limits = c(1,4),
                     breaks = 1:4) +
  papaja::theme_apa()
```
:::
:::

#### EMMs

In addition to the plot, we can get get the actual means for each combination of categories. As with everything, there's a package for it! Just like with `afex_plot()`, we provide the model object and the relevant variables to calculate means for.

```{r}
emmeans::emmeans(mcq_afx, c("mcq", "sticsa_cat"))
```

::: {.callout-note appearance="minimal" title="Exercise"}

**CHALLENGE**: Turn this estimated marginal means table into a nicely formatted table using `kbl()` (and, if you feel up for it, `pivot_wider()`).

::: {.callout-note collapse="true" title="Solution"}

The only information I really want out of this table are the means and confidence intervals. Instead of keeping all the other info, I decided to combine the means and CIs into a single variable using `paste0()`. The rest is just rearranging, relabelling, and making things look good!

```{r}
emmeans::emmeans(mcq_afx, c("mcq", "sticsa_cat")) |> 
  ## convert to tibble to work with more easily
  tibble::as_tibble() |> 
  ## concatenate all the info into a new variable and reformat mcq
  dplyr::mutate(
    mean_ci = paste0(round(emmean, 2), " ",
                "[", round(lower.CL, 2), 
                ", ", round(upper.CL, 2), "]"),
    mcq = stringr::str_to_title(mcq)
  ) |> 
  ## keep only categorical vars and new one
  dplyr::select(mcq, sticsa_cat, mean_ci) |> 
  ## reshape
  tidyr::pivot_wider(
    names_from = sticsa_cat,
    values_from = mean_ci
  ) |> 
  ## reorder
  dplyr::select(mcq, low, high) |> 
  kableExtra::kbl(
    col.names = c("MCQ Condition", "Low Anxiety", "High Anxiety"),
    align = "c",
    caption = "STICSA Post-Test State Anxiety means and 95% confidence intervals"
  ) |> 
  kableExtra::kable_classic() |> 
  kableExtra::add_header_above(header = c(" " = 1, 
                               "STICSA Trait Anxiety" = 2))
```
:::
:::

#### Simple Effects

Finally, we can get tests of the effect between the levels of one variable, within each level of the other. Using the `emmeans::joint_tests()` function, we can use the model object and the name of the variable we want to split by to get tests within each level of that variable.

```{r}
emmeans::joint_tests(mcq_afx, "mcq")
emmeans::joint_tests(mcq_afx, "sticsa_cat")
```

### Mixed Designs

`discovr_16`

#### Detour: Reshaping

```{r}
anx_scores_data |> 
  dplyr::select(id, contains(c("sticsa", "mcq"))) |> 
  tidyr::pivot_longer(cols = contains("state"),
                      names_to = "time",
                      values_to = "sticsa_state",
                      names_pattern = ".*?_(.*?)_.*")
```

#### Fit the Model

```{r}
# fit the model:
mcq_rep_afx <- afex::aov_4(date ~ strategy*looks*personality + (looks*personality|id), data = date_tib)
date_afx #this shows us the model

```

#### Main Effects

```{r}
emmeans::contrast(looks_emm, method = "trt.vs.ctrl", ref = 2, adjust = "holm")


```

#### Two-Way Interactions

```{r}

strat_looks_emm <- emmeans::emmeans(date_afx, c("strategy", "looks"), model = "multivariate")
strat_looks_emm # shows us the means

emmeans::contrast(
  strat_looks_emm,
  interaction = c(strategy = "trt.vs.ctrl", looks = "trt.vs.ctrl"),
  ref = 2,
  adjust = "holm"
  )

strat_pers_emm <- emmeans::emmeans(date_afx, c("strategy", "personality"), model = "multivariate")
strat_pers_emm # display the means
emmeans::contrast(strat_pers_emm, interaction = c(strategy = "trt.vs.ctrl", personality = "trt.vs.ctrl"), ref = 2, adjust = "holm")

looks_pers_emm <- emmeans::emmeans(date_afx, c("looks", "personality"), model = "multivariate")
looks_pers_emm # display the means
emmeans::contrast(looks_pers_emm, interaction = c(looks = "trt.vs.ctrl", personality = "trt.vs.ctrl"), ref = 2, adjust = "holm")

```

#### Three-Way Interaction

```{r}
three_way_emm <- emmeans::emmeans(date_afx, c("strategy", "looks", "personality"), model = "multivariate")
three_way_emm # shows us the means

emmeans::contrast(
  three_way_emm,
  interaction = c(strategy = "trt.vs.ctrl", looks = "trt.vs.ctrl", personality = "trt.vs.ctrl"),
  ref = 2,
  adjust = "holm"
  )
```

## Continuous Predictors

### Mediation

#### Fit the Model

```{r}
infidelity_mod <- 'phys_inf ~ c*ln_porn + b*commit
                   commit ~ a*ln_porn
                   indirect_effect := a*b
                   total_effect := c + (a*b)
                   '
```

mcq_score ~ rmars_num_score

```{r}
mars_mod <- 'mcq_score ~ c*rmars_num_score + b*sticsa_pre_state_score
                   sticsa_pre_state_score ~ a*rmars_num_score
                   indirect_effect := a*b
                   total_effect := c + (a*b)
                   '
```

```{r}
mars_med <- lavaan::sem(mars_mod, data = anx_scores_data,
                        missing = "FIML", estimator = "MLR")
```

#### Results

```{r}
#summarize the model (and round values for convenience)
broom::glance(mars_med)
broom::tidy(mars_med, conf.int = TRUE)
```

### Moderation

#### Centring

Before we fit our model, we will first mean-centre our predictors. This doesn't change the actual model, but it does change the interpretation by setting 0 to be the mean of each variable.

::: {.callout-note appearance="minimal" title="Exercise"}

Use the `scale()` function to mean-centre your variables. Use the help documentation to make sure you use the right arguments.

::: {.callout-note collapse="true" title="Solution"}

The help documentation for `scale()` tells us that we need to give it the variable to centre, then decide whether we want to centre and/or scale. We *do* want to centre, and `center = TRUE` is the default setting, so we don't need to do anything here. However, we *don't* want to scale, and `scale = TRUE` is also the default setting, so we'll need to specify `scale = FALSE`.

Then we just need to `mutate()` accordingly and give our variables some new names, either manually:

```{r}
anx_scores_data <- anx_scores_data |> 
  dplyr::mutate(
    sticsa_trait_score_cent = scale(sticsa_trait_score, scale = FALSE),
    stars_int_score_cent = scale(stars_int_score, scale = FALSE)
  )
```

Or with `across()`, if you did the challenge tasks in Tutorial 06:

```{r}
#| eval: false

anx_scores_data |> 
  dplyr::mutate(
    across(c(sticsa_trait_score, stars_int_score),
           ~scale(.x, scale = FALSE),
           .names = "{.col}_cent")
  )
```
:::
:::
  
#### Fit the Model

The good news is that a moderation model is just a fancy name for your bog-standard linear model, just with an interaction effect, which means we're back to visit our old friend `lm()`. Literally the only new thing is how to specify the interaction. The simplest way is to use the multiplication symbol, `*`, to join together interacting predictors; this will include all the main effects as well as the interaction in the model at once. So, our formula will look like this:

```
outcome ~ predictor1*predictor2
```

From there it's all exactly the same as what we did before in [Tutorial 04](../01_fundRmentals/04_lm.qmd) to fit and inspect the model.

::: {.callout-note appearance="minimal" title="Exercise"}

Fit the model with MCQ score as the outcome, and the centered versions of STARS interpretation anxiety and STICSA trait anxiety as the predictors, including an interaction. Save the model in a new object called `stars_mod_lm`.

::: {.callout-note collapse="true" title="Solution"}

Just to keep things interesting, here's how you can do this with the pipe. The main difference it makes is that you can use the tab autocomplete for these long variable names when typing in the code, but it makes no difference to the resulting model.

```{r}
stars_mod_lm <- anx_scores_data |> 
  lm(mcq_score ~ stars_int_score_cent*sticsa_trait_score_cent,
     data = _)
```
:::
:::

#### Results

::: {.callout-note appearance="minimal" title="Exercise"}

Have a look at the model results. If you feel so inclined, print them out in a nice auto-formatted table as well.

::: {.callout-note collapse="true" title="Solution"}

To just get the parameters table, we can use `broom::tidy()` as before.

```{r}
broom::tidy(stars_mod_lm, conf.int = TRUE)
```

For the fancy one, you can do this with {papaja}, {rempsyc}, or other methods of your choice. I'm going for {papaja} this time.

```{r}
papaja::apa_print(stars_mod_lm)$table |> 
  papaja::apa_table()
```
:::
:::

The tutorial introduces a few ways to explore the nature of the significant interaction. First, the simple slopes output includes some helpful statistical results as well as a Johnson-Neyman plot. For this we'll use the `sim_slopes()` function from the {interactions} package as below. 

```{r}
interactions::sim_slopes( # <1>
  stars_mod_lm, # <2>
  pred = stars_int_score_cent, # <3>
  modx = sticsa_trait_score_cent, # <4>
  jnplot = TRUE, # <5>
  robust = TRUE, # <6>
  confint = TRUE # <7>
  )
```

1. Produce a simple slopes analysis as follows:
2. Use the model stored in the object `stars_mod_lm`,
3. with the centered STARS Interpretation Anxiety score as the predictor,
4. and the centered STICSA Trait Anxiety score as the moderator,
5. including a Johnson-Neyman interval plot,
6. robust estimation of confidence intervals,
7. and CIs instead of SEs.

For a lovely visualisation of the simple slopes analysis, the `interact_plot()` function from the same package produces a beautiful plot with minimal effort. This plot output is also a ggplot object, so you can further add to or customise it from here if you prefer.

```{r}
interactions::interact_plot( # <1>
  stars_mod_lm, # <2>
  pred = stars_int_score_cent, # <3>
  modx = sticsa_trait_score_cent, # <4>
  interval = TRUE, # <5>
  x.label = "STARS Interpretation Anxiety Score", # <6>
  y.label = "Predicted MCQ Score", # <6>
  legend.main = "STICSA Trait Anxiety Score" # <6>
  )
```

1. Produce a simple slopes interaction plot as follows:
2. Use the model stored in the object `stars_mod_lm`,
3. with the centered STARS Interpretation Anxiety score as the predictor,
4. and the centered STICSA Trait Anxiety score as the moderator,
5. with CIs included around the lines,
6. and custom labels for the *x*, *y*, and legend.

\ 

