[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jennifer Mankin",
    "section": "",
    "text": "Dr. Mankin is a senior teaching-focused lecturer in Psychology at the University of Sussex. She is particularly interested in making statistics and coding accessible, enjoyable, and engaging, particularly for learners who aren’t that enthusiastic about the whole endeavour.\nDr. Mankin began teaching at the University of Sussex, originally teaching cognitive psychology and research methods and statistics with SPSS. In the 2019/2020 academic year, Psychology at Sussex switched to R for undergraduate methods and statistics teaching1. Since then, Dr. Mankin has been just on the bright side of being hell-bent on helping anyone who will sit still long enough experience the joy of R.\nThe materials on this website are an attempt to do that: to share some of the hard-won skills and knowledge to support others to get excited about the potential of coding in R."
  },
  {
    "objectID": "about.html#footnotes",
    "href": "about.html#footnotes",
    "title": "Jennifer Mankin",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYep, the timing was just about as bad as it could have been!↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R Training at Sussex",
    "section": "",
    "text": "This is the website for training courses in the programming language R, run by the Methods Teaching Team in the School of Psychology, University of Sussex.\n\n\nAt the moment, our training sessions are only open to members of staff in the School of Psychology at Sussex, or by invitation.\nIf you fit that description, DO X\nIf you do not fit that description but are interested in joining a training course in the future, please register your interest here and we will get in touch when/if there are open sessions available."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "R Training at Sussex",
    "section": "",
    "text": "This is the website for training courses in the programming language R, run by the Methods Teaching Team in the School of Psychology, University of Sussex.\n\n\nAt the moment, our training sessions are only open to members of staff in the School of Psychology at Sussex, or by invitation.\nIf you fit that description, DO X\nIf you do not fit that description but are interested in joining a training course in the future, please register your interest here and we will get in touch when/if there are open sessions available."
  },
  {
    "objectID": "index.html#materials",
    "href": "index.html#materials",
    "title": "R Training at Sussex",
    "section": "Materials",
    "text": "Materials\n\nTutorials\nThe Tutorials section of the site contains tutorial documents designed to accompany live training sessions. They provide explanations, examples, and exercises designed for complete beginners through improvers.\n\n\nWorksheets\nWorksheets are hosted on the Posit Cloud workspace for the training course. You can join the workspace via Canvas.\n\n\nRecordings\nLive sessions are recorded and made available, with automatically-generated captions, as soon as possible after the sessions are complete. View session recordings on Canvas."
  },
  {
    "objectID": "quick_ref.html",
    "href": "quick_ref.html",
    "title": "Quick Reference",
    "section": "",
    "text": "Looking for a function you can’t quite remember how to use? You’re in the right place! The table below is arranged alphabetically by function name, and the linked full name (including relevant package calls) will take you to the help documentation.\n\n\n\n\n\nFunction Name\n\n\nLink to Help Documentation\n\n\nUsed In…\n\n\n\n\n\n\nacross()\n\n\ndplyr::across()\n\n\n10: Reshaping and Merging\n\n\n\n\nanova()\n\n\nanova()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\napa_print()\n\n\npapaja::apa_print()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\napa_table()\n\n\npapaja::apa_table()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nautoplot()\n\n\nggplot2::autoplot()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nc()\n\n\nc()\n\n\n01/02: IntRoduction04: Reporting Linear Models with Quarto10: Reshaping and Merging\n\n\n\n\nclass()\n\n\nclass()\n\n\n01/02: IntRoduction\n\n\n\n\ncontains()\n\n\ndplyr::contains()\n\n\n10: Reshaping and Merging\n\n\n\n\ndata()\n\n\ndata()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nglance()\n\n\nbroom::glance()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nlibrary()\n\n\nlibrary()\n\n\n04: Reporting Linear Models with Quarto08: Analysis10: Reshaping and Merging\n\n\n\n\nlm()\n\n\nlm()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nlmRob()\n\n\nrobust::lmRob()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nmean()\n\n\nmean()\n\n\n01/02: IntRoduction10: Reshaping and Merging\n\n\n\n\nmodel_parameters()\n\n\nparameters::model_parameters()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nnice_table()\n\n\nrempsyc::nice_table()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\npick()\n\n\ndplyr::pick()\n\n\n10: Reshaping and Merging\n\n\n\n\nround()\n\n\nround()\n\n\n01/02: IntRoduction04: Reporting Linear Models with Quarto\n\n\n\n\nrowMeans()\n\n\nrowMeans()\n\n\n10: Reshaping and Merging\n\n\n\n\nsd()\n\n\nsd()\n\n\n10: Reshaping and Merging\n\n\n\n\nselect()\n\n\ndplyr::select()\n\n\n10: Reshaping and Merging\n\n\n\n\nt.test()\n\n\nt.test()\n\n\n01/02: IntRoduction\n\n\n\n\ntidy()\n\n\nbroom::tidy()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nwhere()\n\n\ndplyr::where()\n\n\n10: Reshaping and Merging"
  },
  {
    "objectID": "quick_ref.html#index-of-functions",
    "href": "quick_ref.html#index-of-functions",
    "title": "Quick Reference",
    "section": "",
    "text": "Looking for a function you can’t quite remember how to use? You’re in the right place! The table below is arranged alphabetically by function name, and the linked full name (including relevant package calls) will take you to the help documentation.\n\n\n\n\n\nFunction Name\n\n\nLink to Help Documentation\n\n\nUsed In…\n\n\n\n\n\n\nacross()\n\n\ndplyr::across()\n\n\n10: Reshaping and Merging\n\n\n\n\nanova()\n\n\nanova()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\napa_print()\n\n\npapaja::apa_print()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\napa_table()\n\n\npapaja::apa_table()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nautoplot()\n\n\nggplot2::autoplot()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nc()\n\n\nc()\n\n\n01/02: IntRoduction04: Reporting Linear Models with Quarto10: Reshaping and Merging\n\n\n\n\nclass()\n\n\nclass()\n\n\n01/02: IntRoduction\n\n\n\n\ncontains()\n\n\ndplyr::contains()\n\n\n10: Reshaping and Merging\n\n\n\n\ndata()\n\n\ndata()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nglance()\n\n\nbroom::glance()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nlibrary()\n\n\nlibrary()\n\n\n04: Reporting Linear Models with Quarto08: Analysis10: Reshaping and Merging\n\n\n\n\nlm()\n\n\nlm()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nlmRob()\n\n\nrobust::lmRob()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nmean()\n\n\nmean()\n\n\n01/02: IntRoduction10: Reshaping and Merging\n\n\n\n\nmodel_parameters()\n\n\nparameters::model_parameters()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nnice_table()\n\n\nrempsyc::nice_table()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\npick()\n\n\ndplyr::pick()\n\n\n10: Reshaping and Merging\n\n\n\n\nround()\n\n\nround()\n\n\n01/02: IntRoduction04: Reporting Linear Models with Quarto\n\n\n\n\nrowMeans()\n\n\nrowMeans()\n\n\n10: Reshaping and Merging\n\n\n\n\nsd()\n\n\nsd()\n\n\n10: Reshaping and Merging\n\n\n\n\nselect()\n\n\ndplyr::select()\n\n\n10: Reshaping and Merging\n\n\n\n\nt.test()\n\n\nt.test()\n\n\n01/02: IntRoduction\n\n\n\n\ntidy()\n\n\nbroom::tidy()\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nwhere()\n\n\ndplyr::where()\n\n\n10: Reshaping and Merging"
  },
  {
    "objectID": "quick_ref.html#index-of-topics",
    "href": "quick_ref.html#index-of-topics",
    "title": "Quick Reference",
    "section": "Index of Topics",
    "text": "Index of Topics\nIf you’re looking for a particular section of a tutorial, use this handy summary to jump straight to the section you want.\n\n\n\n\n\nJump to Topic\n\n\n\n\n\n\n01/02: IntRoduction\n\n\n\n\nMaking Mistakes\n\n\n\n\nGlossoRlia\n\n\n\n\nTypes of Data\n\n\n\n\nNumeric\n\n\n\n\nCharacter\n\n\n\n\nLogical\n\n\n\n\nClass and Coercion\n\n\n\n\nObjects\n\n\n\n\nCreating an Object\n\n\n\n\nCalling an Object\n\n\n\n\nUsing Objects\n\n\n\n\nImportant: Overwriting Objects\n\n\n\n\nFunctions\n\n\n\n\nBasics and Help\n\n\n\n\nArguments\n\n\n\n\nUsing Functions\n\n\n\n\nLet’s Get Testing\n\n\n\n\nComparing Groups with t-test\n\n\n\n\n03: Datasets\n\n\n\n\nThe Pipe\n\n\n\n\nDatasets\n\n\n\n\nReading In\n\n\n\n\nViewing\n\n\n\n\nArranging\n\n\n\n\nOverall Summaries\n\n\n\n\nVariables\n\n\n\n\n04: Reporting Linear Models with Quarto\n\n\n\n\nThe Linear Model\n\n\n\n\nData and Codebook\n\n\n\n\nOne Predictor\n\n\n\n\nHierarchial Models\n\n\n\n\nAssumptions Checks\n\n\n\n\nQuarto\n\n\n\n\nGetting Started\n\n\n\n\nCreating a Code Chunk\n\n\n\n\nHeadings and Text\n\n\n\n\nDynamic Reporting\n\n\n\n\nRendering\n\n\n\n\nWell done!\n\n\n\n\n07: Mutate and Summarise\n\n\n\n\nFilter\n\n\n\n\nMultiple Conditions\n\n\n\n\nData Cleaning\n\n\n\n\nSelect\n\n\n\n\n&lt;tidyselect&gt;\n\n\n\n\n09: Questionnaires\n\n\n\n\nMutate\n\n\n\n\nComposite Scores\n\n\n\n\nConditionals\n\n\n\n\nIteration\n\n\n\n\nSummarise\n\n\n\n\nBy Group\n\n\n\n\nIteration"
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "These tutorials are designed to accompany live training sessions, but they also serve as quick-reference guides for all the material covered in those sessions.\n\n\nIn live sessions, it is recommended to open the corresponding tutorial in the Viewer pane in Posit Cloud so that solutions and explanations are easily available. The workbook documents provided for each week will already contain the code to do this.\nHowever, the tutorials can also be easily accessed at any time through this website, so it isn’t necessary to open Posit Cloud to view them - simply use the sidebar to jump to the tutorial you want!\n\n\n\nThe exercises are strongly recommended to build your skills in R. All data and workbooks will be provided on Posit Cloud for completing the exercises.\nSolutions to all exercises are provided in the tutorial as well.\n\n\nSome exercises will be clearly labeled as “Challenges”. These exercises are optional and are meant to go beyond the core tutorial material. However, if you skip them, you will still be able to understand everything that follows; you won’t need to complete them in order to proceed."
  },
  {
    "objectID": "tutorials.html#using-the-tutorials",
    "href": "tutorials.html#using-the-tutorials",
    "title": "Tutorials",
    "section": "",
    "text": "These tutorials are designed to accompany live training sessions, but they also serve as quick-reference guides for all the material covered in those sessions.\n\n\nIn live sessions, it is recommended to open the corresponding tutorial in the Viewer pane in Posit Cloud so that solutions and explanations are easily available. The workbook documents provided for each week will already contain the code to do this.\nHowever, the tutorials can also be easily accessed at any time through this website, so it isn’t necessary to open Posit Cloud to view them - simply use the sidebar to jump to the tutorial you want!\n\n\n\nThe exercises are strongly recommended to build your skills in R. All data and workbooks will be provided on Posit Cloud for completing the exercises.\nSolutions to all exercises are provided in the tutorial as well.\n\n\nSome exercises will be clearly labeled as “Challenges”. These exercises are optional and are meant to go beyond the core tutorial material. However, if you skip them, you will still be able to understand everything that follows; you won’t need to complete them in order to proceed."
  },
  {
    "objectID": "tutorials.html#content",
    "href": "tutorials.html#content",
    "title": "Tutorials",
    "section": "Content",
    "text": "Content\nTutorials are divided into three sections.\n\nFundRmentals\nThe three-part FundRmentals series covers essential basic skills in R, and is designed for absolute beginners who have never seen R before and who have little to no coding experience of any kind.\nBy the end of this series, you will be able to:\n\nNavigate the RStudio IDE\nCreate and work with different types of data\nWork with objects and functions\nPerform calculations and logical tests on single values and vectors\nRead in data from a .csv file into a tibble\nView, summarise, and arrange the order of a tibble\nCreate and render Quarto documents\nPerform and report t-test and linear model analyses\n\n\n\nEssentials\nThe four-part Essentials series is designed for novices with some basic skills in R, and follows on from the FundRmentals series. It covers the core data wrangling and analysis skills that we teach throughout the first year of the undergraduate Psychology course at Sussex, along with extra tips and techniques for efficient and transparent analysis to support dissertation supervisors to help their students.\nBy the end of this series, you will be able to:\n\nFilter cases and select variables, including efficient &lt;tidyselect&gt; semantics\nCreate new variables in a dataset, or change/recode existing ones\nCreate a variety of customised data visualisations\nPerform and efficiently report the results of t-tests, chi-squared tests, correlations, and simple and hierarchical linear models\n\n\n\nImprovRs\nThe four-part ImprovRs series is designed for those with a strong foundation in R who want to move to using R in part or entirely for their data management and analysis process, and follows on from the Essentials series. It covers specific skills in working with questionnaire data, advanced data wrangling, and an introduction to writing functions, with the aim of building a diverse toolbox of R skills.\nBy the end of this series, you will be able to:\n\nWork with labelled Qualtrics data and factors\nCreate standardised subscale scores\nGenerate automatic codebooks for Qualtrics datasets\nReshape (wide/long format) and merge/separate datasets\nWrite custom anonymous and named functions"
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html",
    "href": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html",
    "title": "01/02: IntRoduction",
    "section": "",
    "text": "The Console is deceptively simple: just the &gt; symbol with a flashing cursor after it, waiting for you to type something. However, the Console is the heart of R, where anything you want to do actually happens. Every command that you type, anything you want R to do, goes through here.\nSo - let’s get cracking."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#making-mistakes",
    "href": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#making-mistakes",
    "title": "01/02: IntRoduction",
    "section": "Making Mistakes",
    "text": "Making Mistakes\nBefore we go any further, an affirmation: you will, inevitably, make typos and errors using R. You will write commands that make sense to you that R doesn’t understand; and you will write commands that don’t make sense to you, that R does understand. You will make lots of mistakes, so let’s start there: with errors.\n\n\n\n\n\n\nExercises\n\n\n\nType literally any gibberish, words, keysmashes etc. into the code chunk on the worksheet and press Run (or Ctrl/Cmd + Shift + Enter).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## Keysmash!\naslavb;lj aew aljvb\n\nError: &lt;text&gt;:2:11: unexpected symbol\n1: ## Keysmash!\n2: aslavb;lj aew\n             ^\n\n\n\n## Words!\nAm I a coward? Who calls me villain?\n\nError: &lt;text&gt;:2:4: unexpected symbol\n1: ## Words!\n2: Am I\n      ^\n\n\n\n## Emojis! \n¯\\_(ツ)_/¯\n\nError: &lt;text&gt;:2:1: unexpected input\n1: ## Emojis! \n2: ¯\n   ^\n\n\n\n\n\n\n\nWell, that went about as well as expected.\nIf you haven’t tried this yet, and your code chunk is just ominously staring at you, I’m serious - smash your head into the keyboard if you have to, or let your cat walk on it, or play it as if it were a piano, and press Enter. There’s two important things to learn from this:\n\nTo ask R to do something, you must write them out somewhere (in a code chunk, in the Console) and then run them.\nEventually, inevitably, something that you type WILL produce an error.\n\nFrom our keysmashing above, you will have seen that aslavb;lj aew aljvb, Am I a coward? Who calls me villain?, and ¯\\_(ツ)_/¯ are not valid commands in R. In other words, although each of these has a communicative function for humans, R can’t understand them. In order to get the answer that we want, we have to ask R to do something in a way it can understand, by writing commands it can parse (i.e. decipher) using the R language.\n\n\n\n\n\n\nGlossoRlia\n\n\n\nJust like learning any other language, learning to communicate with R takes time and practice, and it can be very frustrating when you and R can’t seem to understand each other. However, one advantage of learning to talk to R vs learning to speak a human language is that R always works the same way. It doesn’t get angry or sullen or sarcastic; it won’t ignore you or get impatient even if you ask it the same question a thousand times; and even if the response it gives doesn’t make sense to you, there’s always a logical reason for what it does.\nAlthough it certainly is complex, and occasionally quite frustrating, R is just a system for doing computational and analytical tasks. It’s powerful, and the very fact that you can do so much with it also means there’s a lot to learn. But it is comprehensible, and ultimately it’s just a tool to help you do your work well."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#types-of-data",
    "href": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#types-of-data",
    "title": "01/02: IntRoduction",
    "section": "Types of Data",
    "text": "Types of Data\nOne key concept for using R is the different ways it categorises data. “Data” here means any piece of information you put into R - a word, a number, the result of a command or calculation, a dataset, etc. Depending on the type of data you have, R will treat it differently, and some operations only work on certain types of data. So, let’s have a look at how R encodes and deals with different types of data. Here’s well cover three of the most common and important: numeric, character, and logical.\n\nNumeric\nThe first, and most obvious, type of data in R is numbers. Once again, let’s create a new code chunk and see what happens.\n\n\n\n\n\n\nExercise\n\n\n\nType any single number and run the code.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Pick any number at random\n\n3958\n\n[1] 3958\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nRemember that you can run all the code in a code chunk by pressing Ctrl/Cmd + Shift + Enter on your keyboard, or by clicking the green “play” arrow in the top right corner of the chunk.\nYou can also run only a particular line of code, or something that you’ve highlighted, by pressing Ctrl/Cmd + Enter.\n\n\nThis might be what you’d expect. We’ve essentially asked R, “Give me 3958” (or whatever number you put in) and R obliges. The only thing that might be a surprise is the [1] marker, called an index. Basically, R has replied, “The first thing ([1]) that you asked me for is 3958.” We’ll come back to this in a moment.\n\n\n\n\n\n\nExercise\n\n\n\nHow does R handle commas within a number (e.g. to separate the thousands place from the hundreds)? How about full stops for decimals?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n3,958\n\nError: &lt;text&gt;:1:2: unexpected ','\n1: 3,\n     ^\n\n\n\n3.958\n\n[1] 3.958\n\n\n\n\n\n\n\nSo, commas within numbers throw an error. This is because commas have an important role to play in functions, so long numbers must be inputted into R without any punctuation. However, full stops to mark decimal places are just fine.\n\n\n\n\n\n\nGrammar Check\n\n\n\n\n\nTry for a moment switching to Source mode by clicking the Source button in the upper left hand of your Quarto document. You can see that RStudio helpfully marks out the part of the code that isn’t parsable (not in “grammatical” R) with a red ❌ next to the line number, and squiggly red underlining, likely familiar from word processing programmes, under the part of the code that’s causing the issue. It won’t do this for every error, but it’s very helpful for finding “grammatical” errors like extra or missing brackets or misplaced commas.\n\n\n\nNext, let’s try doing some basic maths.\n\n\n\n\n\n\nExercise\n\n\n\nAdd together your shoe size and the number of windows in the room you’re currently in.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n40 + 8\n\n[1] 48\n\n\n\n\n\n\n\nImportant to note here is that we don’t need to type an = to get the answer, just the equation we want to solve and press Enter. Again, we’ve asked R, “Give me 40 + 8” (or whatever numbers you chose) and R replies with the answer.\nYou will not be surprised to learn that you can use R as a calculator to subtract, divide, and multiply as well.\n\n\n\n\n\n\nExercise\n\n\n\nTry subtracting, dividing, and multiplying the same two numbers.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n40 - 8\n\n[1] 32\n\n40 * 8\n\n[1] 320\n\n40 / 8\n\n[1] 5\n\n\n\n\n\n\n\n\nVectors\nLet’s imagine I want to generate some simple participant ID numbers to keep track of the order that they completed my study, and I had 50 in total. I could do this by typing every number out one by one, but this is exactly the kind of tedious nonsense that computers are great at. Instead, we’ll use the operator :, which means “every whole number between”.\n\n\n\n\n\n\nExercise\n\n\n\nPrint out every whole number between 1 and 50.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n1:50\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n\n\n\n\n\n\n\nNotice that the indices mentioned earlier have come up again. The first element after the [n] index is the nth element. Let’s have a look at this some more.\n\n\n\n\n\n\nExercise\n\n\n\nPrint out all the numbers 12 through 30; all of the numbers 23 through 55; and 36, all in one command.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nc(12:30, 23:55, 36)\n\n [1] 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 23 24 25 26 27 28\n[26] 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n[51] 54 55 36\n\n\n\n\n\n\n\nYou may have tried something like this:\n\n12:30\n\n [1] 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30\n\n23:55\n\n [1] 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n[26] 48 49 50 51 52 53 54 55\n\n36\n\n[1] 36\n\n\nAs you can see from the markers, this is three separate commands, because the numbered indices start over from [1] each time. However, we want all those numbers in a single command. To do this, I’m going to use a function called c().\nThis is our first contact with functions in R, and we’ll explore how they work more later on. To use this one, type it out, then inside the brackets, put the numbers you want to collect (or concatenate, or combine), with different groups separated by commas.\n\nc(12:30, 23:55, 36)\n\n [1] 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 23 24 25 26 27 28\n[26] 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n[51] 54 55 36\n\n\nAs you can see from the numbered indices this time, when I put the numbers I want inside the function c(), separated by commas, R collects all of the numbers into a single series of elements, called a vector.\nActually, we’ve been looking at vectors this whole time. Any series of pieces of information in R is a vector (but see Tip box on vectors and elements). When we were looking at single numbers (like 3958 above), we were still getting a vector back from R, but it was a vector with only one element, and thus only [1].\nIf I want the nth element in the vector we’ve just created, (say, the 88th), I can get it out using the numbered markers by indexing with square brackets.\n\nc(12:30, 23:55, 36)[33]\n\n[1] 36\n\n\nWhat I’ve essentially asked R is, “Put all of these numbers into a single vector, and then give me the 33th element in that vector.” As it turns out, the 33th element in that vector of numbers is 36.\n\n\n\n\n\n\nDefinition: Vectors\n\n\n\nA vector is essentially a series of pieces of data, or elements. It is a key basic piece of how data is stored in R. When R returns a vector as the output from a command, each element is numbered in square brackets. These square brackets can also be used to index the vector to get the nth element.\nFor atomic vectors created with c() or similar operations, there are some important rules:\n\nEach element must be scalar (i.e. of length 1)\nAll of the elements must have the same data type (or will be coerced)\n\nFor a complete explanation of vectors (and their more versatile siblings, lists) that’s beyond the scope of this tutorial, see:\n\nThis excellent explainer on vectors and lists\nR for Data Science chapter 20\n\n\n\n\n\nVector Calculations\n\n\n\n\n\n\nExercise\n\n\n\nCreate a vector of every whole number between 37 and 63, and subtract 7 from each one.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nc(37:63) - 7\n\n [1] 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54\n[26] 55 56\n\n\n\n\n\n\n\nThis could be a very tedious process, but here we have an example of a vectorised operation. By default, the operation “subtract 7” is automatically applied to each individual element of the vector.\nWe can do a lot more than this with numbers and data in R, but this is an excellent start. Just one note before we move on about the order in which R performs its calculations.\n\n\n\n\n\n\nOrder of Operations\n\n\n\nMathematical expressions are evaluated in a certain order of priority. You can use brackets to tell R which part of a longer calculation to do first, e.g.:\n\n59 * (401 + 5)\n\n[1] 23954\n\n\nWithout the brackets, the expression is evaluated from left to right, which in this case would give a different answer:\n\n59 * 401 + 5\n\n[1] 23664\n\n\nWhenever there’s any chance for ambiguity, always use brackets to make sure the calculation is performed correctly.\n\n\n\n\n\nCharacter\nCharacters are a more general data category that also includes letters and words. In R, strings of letters or words must be enclosed in either ‘single’ or “double” quotes, otherwise R will try to read them as code:\n\nHello world!\n\nError: &lt;text&gt;:1:7: unexpected symbol\n1: Hello world\n          ^\n\n\n\n\"Hello world!\"\n\n[1] \"Hello world!\"\n\n\nAs you can see here, the first command without quotes throws an error, whereas the second prints out our command just like it did with the single numbers before.\nAn important thing to note is that R sees everything inside a pair of quotes as a single element, regardless of how long it is. You can see this in the indices we saw before:\n\n\"Hi!\"\n\n[1] \"Hi!\"\n\n\"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness...\"\n\n[1] \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness...\"\n\n\nThe [1] markers also tell us that each of the two strings above already constitute vectors, each of length 1. Just like we saw with numbers, above, any number of character strings can be combined into a vector. You can also use the numbered markers to extract the nth element in that vector.\n\n\n\n\n\n\nExercise\n\n\n\nCreate a vector containing the first five animals you think of, then print the 3rd one.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nc(\"bumblebee\", \"squid\", \"falcon\", \"flea\", \"seagull\")[3]\n\n[1] \"falcon\"\n\n\n\n\n\n\n\nThe placement of the quotes is very important - they can’t include the commas. As we said before, R uses commas to separate different elements. So, if you didn’t enclose each word in quotes separately with commas in between, you would have had this odd message:\n\nc(\"bumblebee, squid, falcon, flea, seagull\")[3]\n\n[1] NA\n\n\nNA is a special value in R. It indicates that something is not available, and it usually represents missing data, or that a calculation has gone wrong or can’t be performed properly.\nHere, we asked R for the third element in a vector that, as far as R can tell, only contained one. This is because there’s only one pair of quotes, so all five animals and the commas between them are considered to be one element. Since there isn’t a third element, R has informed us so accordingly - the answer to our query is NA, doesn’t exist. This isn’t what we wanted, but R is not in the wrong here, because it’s done precisely what we told it to do.\n\n\nLogical\nThe final type of data that we’ll look at for now is logical data. In addition to performing calculations and printing out words, R can also tell you whether a particular statement is TRUE or FALSE. To do this, we can use logical operators to form an assertion, and then R will tell us the result.\n\n\n\n\n\n\nExercise\n\n\n\nWrite the following assertions in R:\n\n5 is greater than 10\n6 is less than 12\n27 is less than or equal to 27\n49 does not equal 93\n420 equals 42\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n5 &gt; 10\n\n[1] FALSE\n\n6 &lt; 12\n\n[1] TRUE\n\n27 &lt;= 27\n\n[1] TRUE\n\n49 != 93\n\n[1] TRUE\n\n420 == 42\n\n[1] FALSE\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsserting Equivalence\n\n\n\nThe last couple statements above may have caused you some trouble if the notation is unfamiliar.\nFor “does not equal”, ! is common notation in R for “not”, or the reverse of something. So != can be read as “not-equals”.\nFor “equals”, if you tried this with a single equals sign, you would have had a strange error:\n\n420 = 42\n\nError in 420 = 42: invalid (do_set) left-hand side to assignment\n\n\nThe problem is that in R, the single equals sign = is equivalent to the assignment operator &lt;-, which we’ll learn how to use shortly. Single = also has an important and specific role to play in function arguments. Essentially = is a special operator that doesn’t assert equivalance. Instead, “exactly equals” in R is “double-equals” (or “exactly and only”), ==.\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUse a single command to ask R whether the numbers 2 through 10 are less than or equal to 6.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n2:10 &lt;= 6\n\n[1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE\n\n\n\n\n\n\n\nHere R prints out a value of TRUE or FALSE for each comparison it’s asked to make. So, the first element in the output (TRUE) corresponds to the statement 2 &lt;= 6, the second to 3 &lt;= 6, and so on. This is a vectorised calculation again, as we saw with numeric data before. These vectorised assertions will be absolutely essential to selecting and filtering data that meet particular requirements, or checking our data to find problems."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#class-and-coercion",
    "href": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#class-and-coercion",
    "title": "01/02: IntRoduction",
    "section": "Class and Coercion",
    "text": "Class and Coercion\nWith these short examples, it may be obvious just by looking that 25 is a number and porcupine is a word. However, this isn’t always so straightforward, and there are some situations - such as data checking/cleaning, or debugging - where we might want to check what type of data a certain thing is. To do this, we’ll need another new function, class(). This function will print out, as a character, the name of the data type of whatever is put into the brackets.\n\n\n\n\n\n\nExercise\n\n\n\nUse the class() function to get R to print the values \"numeric\", \"logical\", and \"character\".\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## Any numeric vector will do\nclass(216907)\n\n[1] \"numeric\"\n\n## You can also use a longer vector of numbers\n## as long as they are all numbers!\nclass(c(4:291, -1, 38.7, 100000000))\n\n[1] \"numeric\"\n\n## Logical has two options\n## Create a vector of TRUEs and FALSEs\nclass(TRUE)\n\n[1] \"logical\"\n\n## Create a vector that outputs logical values (now you're thinking with functions!)\nclass(c(6 &gt; 4, 10 == 37, 3 != 8))\n\n[1] \"logical\"\n\n## Character\nclass(\"antidisestablishmentarianism\")\n\n[1] \"character\"\n\n\n\n\n\nWhat data type does R give you if you combine numbers and characters in c()?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## Again, anything will do\n\nclass(c(93, -1905, \"avocado\"))\n\n[1] \"character\"\n\n\n\n\n\n\n\nSomething interesting has happened here. Recall that atomic vectors created with c() must all have the same data type. Here, we combined two types of data: numeric and character. We didn’t get an error - instead, without warning or telling us, R quietly converted the entire vector to character type. This forcible conversion is called coersion.\n\n\n\n\n\n\nCoersion\n\n\n\nCoersion is when a piece of data is forcibly changed from one data type to another. This is sometimes intentional, but it can happen unintentionally (and without any warning or fanfare!), so is a common source of errors.\nCoersion follows a hierarchy; data types on the left can be coerced into the types further along to the right.\nlogical ==&gt; integer ==&gt; double (numeric) ==&gt; character\nAs we saw previously, you can check the data type of a vector with class(). You can also check if a vector is a particular type (and receive a logical vector in response) with the is.*() family of functions. (The * notation refers to a placeholder for many different options, such as is.numeric, is.character, etc.)\nYou can similarly (try to) coerce a vector into a particular data type with the as.*() family of functions.\n\n\nThis explains why our vector from the last exercise was a character vector - since the vector contained at least one character element, everything else in the vector was coerced to the same type. This can cause problems when, for example, numeric data is coerced into character data, even though it still looks like numbers.\nEven though we can do mathematical operations on numbers, we can’t do them on characters; it should be clear that asking e.g. what is \"tomato\" - 7 is nonsense. However, this is the case even if all of the data are numerals! For example:\n\n## No problem here; all numbers\nc(2:20, 45) - 7\n\n [1] -5 -4 -3 -2 -1  0  1  2  3  4  5  6  7  8  9 10 11 12 13 38\n\n## Doesn't work\nc(2:20, \"45\") - 7\n\nError in c(2:20, \"45\") - 7: non-numeric argument to binary operator\n\n\nEven though “45” looks like a number, because it’s in quotes, R thinks that it’s a character, and will refuse to do the calculation, in the same way that it would refuse to do it with “tomato”."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#objects",
    "href": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#objects",
    "title": "01/02: IntRoduction",
    "section": "Objects",
    "text": "Objects\nR is a programming language, but (being created by speakers of natural language) it has many features similar or analogous to natural languages. In this section, we’ll cover the basic “grammar” of R, including how R understands what you ask it to do.\nIn a similar way that the basic unit of many languages is the word1, the basic unit of the R programming language is the object. This section will explore the basics of what an object is and some of their key features in R.\n\n\n\n\n\n\nDefinition: Objects\n\n\n\nObjects are the basic elements that R is built around - the equivalent of words. An “object” in R is any bit of information that is stored with a particular name. Objects can hold anything, from a single number or word to huge datasets with thousands of data points or complex graphs. These named objects are the main way you, the programmer, can store, retrieve, and interact with information in R.\n\n\n\nCreating an Object\nAlthough we have done quite a bit in R so far - creating vectors, doing calculations, etc. - you may notice that we haven’t stored this information anywhere. To store the output of code for further use, it needs to be assigned to an object using the assignment operator, &lt;-. Once an object is created, it will appear in the Environment pane.\n\n\n\n\n\n\nClear Your Environment\n\n\n\nAt the moment your Environment should be empty. As a reminder, Environment is by default the first (leftmost) tab in one of your four main windows in RStudio, probably the one on the top right.\nIf this window is blank except for “Environment is empty”, you’re ready to go. If for some reason it isn’t empty, click the broom icon to clear everything from your Environment before you get started, as indicted in the image below. (There will be a very ominous-sounding “Are you sure?” pop-up, but just click “Yes”.)\n\n\n\nFirst, let’s look at the foundational structure of almost everything you will do in R:\nobject &lt;- instructions\nThis is “pseudo-code”, or a “general format” for a command in R. It isn’t valid R code, but is rather intended as a midpoint between natural language and R to help make it clear how the code works. You can read this code as, “An object is created from (&lt;-) some instructions.”\n\nobject: Objects can be named almost anything (although see Naming, below). The object name is a label so you, the analyst, can find, refer to, and use the information you need.\n&lt;-: The assignment operator &lt;- has single job: to assign output to names, or in other words, to create objects.\ninstructions: Any amount of code that produces some output, which is what object will contain.\n\n\n\n\n\n\n\nNaming Objects\n\n\n\n\n\nCOMING SOON\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nThink of a research scenario familiar to you with two independent groups. You’re welcome to draw from your own research or expertise, but you should choose something with numerical scores. Some ideas include:\n\nReaction times on a button-pressing task from a control and an experimental intervention group\nStatistics anxiety scores from first and second year UG students\nQuiz marks from students with practicals scheduled 9am and students with practicals at 6pm\n\nMake a note of the scenario you chose. Then, create two new objects: one that contains a vector of seven scores from the first of the two groups, and the second that has seven different scores from the second group.\nHint: Just make up some numbers!\n\n\n\n\n\n\nSolution\n\n\n\n\n\nChoosing scenario 3, this vector contains some hypothetical quiz marks from each class.\n\nquiz_9am &lt;- c(75, 58, 62, 14, 33, 67, 55)\nquiz_6pm &lt;- c(45, 90, 27, 65, 39, 77, 48)\n\nLet’s have a look at this command. On the left side I’ve written the name I want my new object to have, which I’ve called quiz_9am[^1]. Next, the assignment operator &lt;- assigns whatever comes after it to the object label quiz_scores_9am. Finally, I’ve written instructions for what I want this object to contain: in this case, a vector of numbers that I’ve made up, but that reasonably look like quiz scores.\n[^1]: I could have called it anything, like the_first_example_of_an_object_InThisSection.so.far or made_upQuizScores.fornineamclass or anything else that follows R’s naming conventions. However, it’s a good idea to name your objects something brief and obvious, so you can remember what they contain.\nIf you haven’t done this yet, do so now, even if you’ve looked at the solution rather than trying it for yourself first. Once you’ve typed the command, there’s a final step to actually create the object: you have to run the command in order for it to take effect. As a reminder, you can do this by clicking the green ▶️ button in the upper right corner of the code chunk, or by pressing Ctrl/Cmd + Enter when your cursor is blinking on the same line as the code you want to run.\n\n\n\n\n\nAssuming your code is valid, you should see a green bar appear along the left-hand side of the code chunk when you run the code, but you might notice that there’s no printout that appears under the code chunk, as there was previously. In fact, if the code ran successfully, it might look like nothing happened at all. To find out what did happen, look your Environment pane. You should now see a new section, “Values”, and underneath the name of your new object and what it contains. Success!\n\n\nCalling an Object\nFor any object, from the most simple to the most complex, you can always see what’s in it by calling the object. This simply means that you type the name of the object and run the code. R will print out whatever is stored in the object.\n\n\n\n\n\n\nExercise\n\n\n\nCall both of the objects you just created.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nReplace with the name of the object you created, if you did something different.\n\nquiz_9am\n\n[1] 75 58 62 14 33 67 55\n\nquiz_6pm\n\n[1] 45 90 27 65 39 77 48\n\n\n\n\n\n\n\nThis output looks just like what we saw earlier, when we just asked R to print out a vector of numbers. In essence, the object names are just labels for storing and referring to the information they contain.\n\n\n\n\n\n\nCreating vs Calling\n\n\n\nThese two actions are the essential basis of everything you will do in R. All of your code will, at base, either create an object, or call an object. (Changing an existing object, as we’ll see shortly, is the exact same procedure as creating one from scratch.)\nWhen you create an object using the assignment operator (&lt;-), the object is created but is not printed out. This is because R always does only and exactly what you ask it to do, and using the assignment operator only tells R to assign something to an object, not to print it out.\nWhen you call an object, the current contents of that object are printed out, but that object is not changed - you only reproduce a copy of its contents for review. To create or change an object, you must use the assignment operator to assign the output to a new (or existing) object name.\n\n\nLet’s make all of this a bit more concrete by seeing how we can use objects effectively.\n\n\nUsing Objects\nSince objects are convenient reference labels for the information they contain, we can work with them as if they were the information they contain. In this case, our objects contain numbers, so we can use them for numerical calculations.\nFor instance, we might want to know what the mean mark was for this sample of quiz marks. To do this, we could make use of a very handy function, mean(), as follows:\n\nmean(quiz_9am)\n\n[1] 52\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCalculate the mean of each of the two sets of scores you created.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhether you save the output of the mean() command is up to you!\n\nmean(quiz_9am)\n\n[1] 52\n\nmean(quiz_6pm)\n\n[1] 55.85714\n\n\n\n\n\nCalculate the difference in the mean of each of the two sets of scores.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHere are two options for accomplishing this.\nThe first option is to save each mean value in a new object (if you didn’t do that already), then subtract one mean from the other. This is very easy to read, but a bit inefficient.\n\nmean_9am &lt;- mean(quiz_9am)\nmean_6pm &lt;- mean(quiz_6pm)\n\nmean_9am - mean_6pm\n\n[1] -3.857143\n\n\nThe second option is to do everything in one command, which takes a bit more effort to parse but is more succinct.\n\nmean(quiz_9am) - mean(quiz_6pm)\n\n[1] -3.857143\n\n\n\n\n\nWhat is the class of these objects?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nEither one will do.\n\nclass(quiz_9am)\n\n[1] \"numeric\"\n\n\nSo, an object has the class of the data it contains.\n\n\n\n\n\n\n\n\n\n\n\nObject Names vs Strings\n\n\n\nYou may have been surprised to see that the class of these objects is numeric, rather than character - even though the name of the object is a character string. To find out the class of the object, R looks at what that object contains, not at the name of the object itself. We already saw that quiz_9am (or whatever your object is called) contains only numbers; so, R tells us that it’s a numeric vector.\nOne more example to emphasize this point, because it’s often a source of confusion when starting out with R. If we want to ask R the class of the string “quiz_9am”, we would need to put it in quotes, and we’d get a different answer:\n\nclass(\"quiz_9am\")\n\n[1] \"character\"\n\n\nThe key thing here is that objects have the class of the data they contain, and are not character data; and whenever you want to use an object, you must not use quotation marks. On the other hand, if you want to input character data into R, you must use quotation marks. Otherwise, R will look for an object or function with that name, which will likely produce a “cannot find object” error.\n\n\nBecause we’ve used the assignment operator, R doesn’t print out the years. Instead, the output of our calculation is saved as the object birth_year. Hmm - didn’t we already have an object called birth_year, though? What happened to it?\n\n\n\n\n\n\nImportant: Overwriting Objects\n\n\n\nYou might notice that we already had an object called birth_year that we created above. R, again, does only and exactly what you ask it to do. Unlike, say, a word processer, that will give you a warning if you try to save two documents in the same folder with the same name, R won’t ask you if you’re sure you want to overwrite an existing object with new information - it will just do it. If you have a look in your Environment, you will see that the previous version of birth_year, containing only your birth year, has been quietly replaced with the new one containing the vector of birth years you just created.\nThis can be a good thing, because you can easily update the information stored in an object with changes, edits, or new information. However, it also means that you can overwrite or replace data when you don’t want to, if you use the same object name.\nThis is why it is so important to keep track of all of the commands and changes you make to your data. If you accidentally replace your dataset with, say, a single word or number with an error in your code, you can easily retrace your steps and avoid redoing work.\nIf you are interested in understanding this process of assigning and replacing the contents of objects better, the aside below explains it in more depth.\n\n\n\n\n\n\nCan you actually change an object?\n\n\n\n\n\nThink of objects as boxes. The names of the objects are only labels, and you can store anything you like inside them. However, unlike in the physical world, objects in R cannot truly change. You can put stuff in and take stuff out, and that’s pretty much it. Unlike boxes, though, when you take stuff out of objects, you only take out a copy of its contents. The original contents of the box remain intact. Of course, you can do whatever you want (within limits) to the stuff once you’ve taken it out of the box, but you are only modifying the copy. The key thing to remember is that unless you put that modified stuff into a box, R will forget about it as soon as it’s done with it. In other words, if you want to “save” any changes you make, you must assign them to an object in order to keep them.\nNow, as you probably know, you can call your boxes (objects) whatever you want (again, within certain limits). This means that that you can call the new box the same as the old one, as we saw with birth_year above. When that happens, R basically takes the label off the old box, pastes it on the new one, and burns the old box. So even though some operations in R may look like they change objects, what’s actually happening is that R copies their content, modifies it, stores the result in a different object, puts the same label on it, and discards the original object. Understanding this mechanism will make things much easier!\nPutting the above into practice, this is how you “change” an R object:\n\n# put 1 into an object (box) called a\na &lt;- 1\n\n# copy the content of a, add 1 to it and store it in an object b\nb &lt;- a + 1\n\n# copy what's inside b and put it in a new object called a\n# discarding (\"overwriting\") the old object a\na &lt;- b\n\n# now see what's inside of a\n# (by copying its content and pasting it in the console)\na\n\n[1] 2\n\n\nOf course, you can just cut out the middleman (creating an object b). So to increment a by another 1, we can do:\n\na &lt;- a + 1\n\na\n\n[1] 3\n\n\n\n\n\n\n\nWe will talk further about using scripts and writing multiple commands below; but first, we’ll need to have a look at a very important type of object in R: the function."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#functions",
    "href": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#functions",
    "title": "01/02: IntRoduction",
    "section": "Functions",
    "text": "Functions\nFunctions are like verbs in the R language - they’re how R does anything. In order to use them, you need to “translate” the command you want to give R into a verb (function) it can understand.\n\nBasics and Help\nLet’s look at an example of how this translation might work. For this example, I’m going to use a number I generated earlier: the mean of the quiz_6pm group, which was 55.8571429, which I’d like to round to two decimal places - a common task for reporting results in APA style.\nIf we want R to do this for us, we have to write this command in a way that R can understand. First, we need to know what function corresponds to the English verb “round” - that is, what function will do the same action that we want R to perform. We’re lucky in this case: the function in R is also called round().\nWe know that we’re looking at a function in R because functions often have a name followed by brackets (and nothing else in R does). That is, they have the general form function_name(). Inside the brackets, we can add more information to the function to complete our command, although not all functions require any more information.\n\n\n\n\n\n\nExercise\n\n\n\nTry running the round() function.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nround()\n\nError in eval(expr, envir, enclos): 0 arguments passed to 'round' which requires 1 or 2 arguments\n\n\nUnsurprisingly, R has given us an error. This is an informative error, though - that is, the error gives of some sort of intelligible clue about what’s gone wrong. Namely, it tells us that round() can’t just work without additional information (i.e. “required arguments”). Imagine, for instance, if you wanted a colleague to round 55.8571429 to two decimal places, and in order to ask them to do that, you just shouted “ROUND!” at them. Similarly, R has objected to this, telling you that it needs more information in order to do what you’ve asked it to.\n\n\n\n\n\nWhat we want to do, “Round the number 55.8571429 to two decimal places”, has two more important pieces of information that we need to tell R: what number we want to round (55.8571429) and how many decimal places we want to round it to (2). So, how do we say this in R? To find out, let’s look at the help documentation.\n\n\n\n\n\n\nExercise\n\n\n\nOpen the help documentation for the round() function by running ?round() or help(round) in the Console.\n\n\n\n\n\n\n\n\nHelp Documentation\n\n\n\nHelp documentation is information, like instruction manuals, built into R about how individual functions work. Function documentation varies wildly in helpfulness and completeness, but it’s a useful place to check first if you want to find out what a function does. You can access the help documentation in a few different ways: by running ?function_name or help(function_name) in the Console, or by clicking on the “Help” tab in the Files section of RStudio and using the Find box to search for the function.\n\n\nThe first section, “Description”, varies quite a bit in intelligibility, depending on how complex the function is. Here, if we ignore the information about the other function including in this document, we can see that we have a useful description of round() that tells us that it rounds numbers (that’s a good sign) to a certain number of decimal places. That’s exactly what we want, so how do we use it?\nLet’s scroll down to “Usage”, which gives examples of what the function looks like. You can see that the basic structure of this function is round(x, digits = 0). It seems like we need to add some more information in the brackets of our function - but how do we interpret x and digits = 0?\n\n\nArguments\nThe information inside a function’s brackets to give it the information it needs to work are called arguments. Each argument in a function is separated by a comma, so we can see from round(x, digits = 0) that the round() function can take two arguments. How many arguments a function has depends on the function; some (like Sys.Date()) don’t need any arguments to run. One of the most useful parts of a function’s help documentation is the “Arguments” section, which tells you what each of the function’s arguments are and how to use them.\nThere are two main types of arguments: named and unnamed arguments. Conveniently, the arguments of round() give us one example of each.\n\nUnnamed Arguments\nThe first argument to round() is simply x. Just like in maths, x is a placeholder for some number or numbers (a “numeric vector”, which should sound familiar now) that you want to pass to the function. This is common notation in many functions: x, often the first argument in a function, is often the placeholder for the information you want to use the function on. In our case, we just have one number we want to round, so that’s what we should replace with x.\nThis argument has no default so it must be provided, or the function won’t run.\n\n\nNamed Arguments\nThe second argument of round() is a named argument, digits = 0. You can think of named arguments like settings that change the way a function works, often with only certain allowable values. Here we can see that the name of the argument is digits; the name before the = sign tells R which setting we want to change.\nThe help documentation tells us that digits should be an “integer indicating the number of decimal places…to be used.” We can also see in “Usage” that this argument has a default value, digits = 0. That means that if we don’t explicitly include the argument digits when we use the function, by default the round() function will round the number you give it to 0 decimal places. Named arguments frequently, but not always, have a default, and it’s important to check so the function doesn’t quietly do something unexpected.\nDefault values of arguments are really useful, because the default is usually the most frequently used setting. It means you don’t have to specify every single aspect of a function every time you use it, as long as you want the function to work that way! In our case, we actually wanted round() to round to two decimal places, not 0. So, in our command, we should change the setting from the default, 0, to 2.\n\n\n\nUsing Functions\nNow that we know what both of these arguments mean, we can change them to actually translate the English sentence “Round the number 55.8571429 to two decimal places” into a command that R can work with. We’ll explicitly write out each argument so we know what they are doing.\n\n\n\n\n\n\nExercise\n\n\n\nUse the round() function to round 55.8571429 to two decimal places.\nIf you prefer, you can do this with one of the means you calculated for your own scores earlier.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## Using the actual value from my earlier calculation\nround(55.85714, 2)\n\n[1] 55.86\n\n## Using a nested function - that is, calculating the mean and then rounding it!\nround(mean(quiz_6pm), 2)\n\n[1] 55.86\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrder of Arguments\n\n\n\n\n\nIf you want to, you can achieve the same result by changing the order of the arguments. Because we have written the names of both arguments, R can still do what we want it to do:\n\nround(digits = 2, x = 55.85714)\n\n[1] 55.86\n\n\nWe can also, to some degree, drop the names of the arguments, as long as R can still understand what we’re trying to do:\n\nround(digits = 2, 55.85714)\n\n[1] 55.86\n\n\nHere I left out the x =. R can still understand this because round() only takes two arguments, and we explicitly told it what value belongs to digits, so it assumes the second number must be x.\n\nround(55.85714, 2)\n\n[1] 55.86\n\n\nThis time I dropped both argument names. R can still understand this because when you don’t specify which input goes with which argument, R will assume they should go in the default order given in the help documentation. So, R has automatically assigned 55.85714 to x and 2 to digits, which is what we wanted.\nAs I use R more and more, I find that I name arguments more consistently, even though I know how the function works and dropping them is more efficient (at least in terms of typing). That’s because when I come back from lunch, or the next day, or six months later to revisit the same code, it’s much easier to recall what it all means when it’s well-annotated. So, I strongly recommend getting in the habit of including argument names in your code as a favour to your future self, and to avoid situations like this:\n\nround(2, 55.85714)\n\n[1] 2\n\n\nHere, since we didn’t specify, R assumed that 2 was the number we wanted to round. This isn’t what we wanted - but R has no way of knowing this. It always assumes that what we typed was precisely what we intended to ask R to do.\n\n\n\n\nPassing Multiple Values to Arguments\nA last important aspect of using functions is to remember that each argument in a function can only take a single object or value as input. For example, we saw above that we put the single value 55.85714 into the x argument of round(). But what if we wanted to round more than one number? We don’t want to have to write a new round() command for every number, even though we could do this if we particularly enjoyed doing a lot of tedious and repetitive typing:\n\nround(55.85714, 2)\n\n[1] 55.86\n\n## ughhhh\nround(59.54, 2)\n\n[1] 59.54\n\n## noooooo :(\nround(0.198, 2)\n\n[1] 0.2\n\n## thanks I hate it\n\n\n\n\n\n\n\nExercise\n\n\n\nBefore you go on, have a go using a single round() command to round all three numbers at once.\nHint: Refer to Vectors.\n\n\nSo what happens if we try to put all of those numbers into round()? We might first try this:\n\nround(55.85714, 59.54, 0.198, 2)\n\nError in eval(expr, envir, enclos): 4 arguments passed to 'round' which requires 1 or 2 arguments\n\n\nOnce again, R tells us that this doesn’t work by throwing an error. R has tried to do what we wanted, but the round() function only allows a max of two arguments, and we’ve given it four. Behind the scenes, R has tried to run round(x = 55.85714, digits = 59.54... and can’t proceed from there because it doesn’t know what to do with the last two numbers. So, what we need to do is find a way to put all three numbers that we want to round into the first x argument together. If only there was a way to concatenate them together…\nYou may have guessed where this is going: one method we could use would be to put the three numbers we want to round into a single object, and then pass that object to round() as the x argument. We already saw that we can combine any number of things together into a single vector using the c() function.\n\n\n\n\n\n\nSolution\n\n\n\n\n## Create an intermediate object to contain the numbers\nnumbers &lt;- c(55.85714, 59.54, 0.198)\nround(numbers, digits = 2)\n\n[1] 55.86 59.54  0.20\n\n## Put the vector of numbers into round() directly\nround(c(55.85714, 59.54, 0.198), digits = 2)\n\n[1] 55.86 59.54  0.20\n\n\n\n\nHere we can see a good example of a function inside another function. You can stack, or “nest”, functions inside each other like this as much as you like, although it can become difficult to read the code or keep track of what it’s doing. (There’s a great solution to this problem that we’ll make extensive use of in the future: the pipe operator.)\nThat’s looking like some proper R code! Very nicely done.\n\n\n\n\n\n\nHelp Documentation, Revisited\n\n\n\nBefore we leave the round() function altogether, let’s take a look at two more useful sections of the help documentation. Depending on what you are trying to do, the “Details” section can tell you more about how exactly the function works - how it behaves in certain situations, or how it handles unusual or difficult cases. If a function isn’t doing what you expect it to, this is a good place to look for an explanation.\nFinally, at the end of the documentation you can find the “Examples” section. If you are learning to use a new function, this section can give you a template for writing your own commands. You can also click the “Run examples” link, which will run the code in the Examples section for you so you can see what the function will do."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#lets-get-testing",
    "href": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#lets-get-testing",
    "title": "01/02: IntRoduction",
    "section": "Let’s Get Testing",
    "text": "Let’s Get Testing\nLet’s put all of this together and have a look at what we can already do with the skills in this tutorial. R has many, many uses, but one of its core purposes is statistical analysis - and we already know more than enough to do this.\n\nComparing Groups with t-test\nWe’ve created two objects that contain scores from two different groups - scores we made up, but we will get to real data soon (in the next tutorial!). For now, one common statistical test we could run on data like this is a t-test, which is a hypothesis test essentially quantifying whether scores come from the same or different populations.\nThe function to run a t-test in R is t.test(), so let’s have a go!\n\n\n\n\n\n\nExercise\n\n\n\nBring up the help documentation for t.test() and use it to run a t-test comparing your two sets of scores.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nt.test(quiz_9am, quiz_6pm)\n\n\n    Welch Two Sample t-test\n\ndata:  quiz_9am and quiz_6pm\nt = -0.33119, df = 11.969, p-value = 0.7462\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -29.23978  21.52550\nsample estimates:\nmean of x mean of y \n 52.00000  55.85714 \n\n\n\n\n\n\n\nThere are a lot of options in the t.test() function, which can be used, through different arguments, to run almost any variety of t-test you can think of. In this case, though, the code is quite simple, because we want all the default settings (for a two-sample, independent test), so we only need to provide x and y, our two numeric vectors.\nNote that the output mentions “Welch Two Sample t-test”, which is a robust version of the test that does not assume equal variances. This is the version that is taught to undergraduates, because we have not at this point introduced the process of assumption testing. If you definitely know that the variances are equal and you definitely want Student’s t-test, you can instead change the default setting:\n\nt.test(quiz_9am, quiz_6pm, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  quiz_9am and quiz_6pm\nt = -0.33119, df = 12, p-value = 0.7462\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -29.23255  21.51826\nsample estimates:\nmean of x mean of y \n 52.00000  55.85714 \n\n\nIn the next tutorial, we’ll see how to turn this rather ugly R output automatically into beautifully formatted reporting like this:\n\nWe compared mean scores between two groups, one who took the quiz in a 9am practical session (M = 52) and the other who took the quiz in a 6pm practical session (M =55.86, Mdiff = -3.86). There was no statistically significant difference in scores between timing groups (t(12) = -0.33, p = 0.746, 95% CI [-29.23, 21.52])."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#footnotes",
    "href": "tutorials/psychrlogy/01_fundRmentals/01_02_intro.html#footnotes",
    "title": "01/02: IntRoduction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAs a linguist I have to note, one, words don’t exist, and two, the closest linguistic term for what an object is is probably “lexeme”. “Word” will get you in the right vicinity, though, conceptually. If you’d like to dive down this rabbit hole (rabbit-hole?) this Crash Course video on morphology is a good place to start.↩︎"
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/03_datasets.html",
    "href": "tutorials/psychrlogy/01_fundRmentals/03_datasets.html",
    "title": "03: Datasets",
    "section": "",
    "text": "Libraries\nReading in, viewing and summarising datasets\nSubsetting with `$`, `pull()`\nUseful verbs: count, tally, mean, sd, min, max, etc.\nQuarto: chunk options, inline code, automatic numbering, rendering\nBase R visualisations"
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/03_datasets.html#overview",
    "href": "tutorials/psychrlogy/01_fundRmentals/03_datasets.html#overview",
    "title": "03: Datasets",
    "section": "Overview",
    "text": "Overview\nThis tutorial is focused on working with datasets, and on writing up the findings from those datasets using Quarto documents. The tutorial covers key functions and tips for reading in, viewing, summarising, and working with datasets, and then walks through the process of setting up and producing a Quarto report, including how to dynamically report results and render a final document to a variety of formats.\nTo kick off, however, we’ll start with an essential piece of R code: the pipe."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/03_datasets.html#the-pipe",
    "href": "tutorials/psychrlogy/01_fundRmentals/03_datasets.html#the-pipe",
    "title": "03: Datasets",
    "section": "The Pipe",
    "text": "The Pipe\nIn the previous tutorial, we saw some examples of “nested” code - functions within functions, as below:\nFor one or two levels of nesting, this is still legible, but can quickly become very difficult to track. One solution is to use the pipe operator, |&gt;. The pipe “chains” commands one after the other by taking the output of the preceding command and “piping it into” the next command, allowing a much more natural and readable sequence of steps. The pipe version of the above might look like this:\n\n\n\n\n\n\nDefinition: Pipe\n\n\n\nThe pipe operator may appear in two formats.\n\nThe native pipe, |&gt;. This is the pipe we will use throughout these tutorials. It is called the “native” pipe because it is inbuilt into R and doesn’t require any specific package to use.\nThe {magrittr} pipe, %&gt;%. This pipe comes from {tidyverse}, and in particular requires the {magrittr} package to use. You will very commonly see this pipe in scripts, Stack Overflow posts, from ChatGPT, etc. as the native pipe was only introduced to R in 2022.\n\nIn most use-cases, including almost all of the code we will learn in these tutorials, the two pipes are interchangeable and will result in the same output.\nConceptually, the pipe works by putting whatever is put into it into the first argument of whatever comes after it. Many functions - both packages and functions from the {tidyverse} and not - are already set up so that the first argument is the data, and {tidyverse} functions are explicitly designed this way in order to work best with the pipe. For functions where this is not the case, you can explicitly determine where the piped-in object should go using a “placeholder”.The most noticeable difference is that the native pipe placeholder is _, while the magrittr pipe placeholder is ..\n\n\n\n\n\n\nPipe Example\n\n\n\n\n\nImagine we wanted to bake a Victoria sponge cake using R. Translating the steps into R, we might get something like this:\n\ningredients |&gt; \n  mix(order = c(\"wet\", \"dry\")) |&gt; \n  pour(shape = \"round\", number = 2, lining = TRUE) |&gt; \n  bake(temp = 190, time = 20) |&gt; \n  cool() |&gt; \n  assemble(filling = c(\"buttercream\", \"jam\"), topping = \"icing_sugar\") |&gt; \n  devour()\n\nError in devour(assemble(cool(bake(pour(mix(ingredients, order = c(\"wet\", : could not find function \"devour\"\n\n\nAt each step, |&gt; takes whatever the previous step produces and passes it on to the next step. So, we begin with ingredients - presumably an object that contains our flour, sugar, eggs, etc - which is “piped into” the mix() function. The output of that function might be all our ingredients mixed together in a bowl, which is then piped into the pour() function, and so on.\nNotice for example, the function cool(), which doesn’t appear to have anything in it. It actually does: the cool() function would apply to whatever the output of the bake() function was above it."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/03_datasets.html#datasets",
    "href": "tutorials/psychrlogy/01_fundRmentals/03_datasets.html#datasets",
    "title": "03: Datasets",
    "section": "Datasets",
    "text": "Datasets\n\nReading In\nThe first step in any data analysis process will be getting a hold of some data! This can be a complex procedure, so to keep it as streamlined as possible, we will always recommend the following steps:\n\nAlways use a project file.\nAlways use the same folder structure.\n\n\n\n\nViewing\n\n\nArranging\n\n\nOverall Summaries\n\nBase R\nThe quickest and easiest check for a whole dataset is the base R function summary(). This function doesn’t do anything fancy (at all) but it does give you a very quick look at how all the variables have been read in, and an early indication if there’s anything wonky going on.\n\nExample\n\nsummary(my_tibble)\n\nHere, for example, notice the age variable. This should be a numeric variable, but clearly something has gone pear-shaped, because it instead seems like a character variable. Compare this to, for example, OTHER EXAMPLE, which has some descriptive information about the distribution of values in the variable, which indicates that it has been successfully read as numeric.\nWe will ignore the age issue for now until we cover how to make changes to the dataset in Tutorial 5\n\n\n\n{datawizard}\nBesides the basic summary, there are many ready-made options in various packages to quickly produce summary tables. At the UG level, students are introduced datawizard::describe_distribution(), which is one such function. To use it, simply put the name of the dataset object inside the brackets.\n\n\n\n\n\n\nTip\n\n\n\nBesides its default settings, the output can be further customised to add or remove particular statistics; see the help documentation.\n\n\n\nExample\n\ndatawizard::describe_distribution(my_tibble)\n\n\n\n\n\nVariables\nOnce we’ve had a look at the whole dataset, it’s time to drill down into individual variables. We may want to calculate quick descriptives or investigate what’s going on with particular variables that seem to have issues (as we saw with age above). For any of these tasks, we’ll look at variables one at a time by subsetting or otherwise pulling them out of the dataset, then calculating some information about them.\n\nSubsetting\n\n\nCounting\n\n\nDescriptives\n\n\nVisualisations"
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/04_lm.html",
    "href": "tutorials/psychrlogy/01_fundRmentals/04_lm.html",
    "title": "04: Reporting Linear Models with Quarto",
    "section": "",
    "text": "This tutorial covers how to run, inspect, and report a linear model in R. For the report portion, we will cover some key features of dynamic reporting in Quarto and how to write and render professionally formatted documents."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/04_lm.html#overview",
    "href": "tutorials/psychrlogy/01_fundRmentals/04_lm.html#overview",
    "title": "04: Reporting Linear Models with Quarto",
    "section": "",
    "text": "This tutorial covers how to run, inspect, and report a linear model in R. For the report portion, we will cover some key features of dynamic reporting in Quarto and how to write and render professionally formatted documents."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/04_lm.html#the-linear-model",
    "href": "tutorials/psychrlogy/01_fundRmentals/04_lm.html#the-linear-model",
    "title": "04: Reporting Linear Models with Quarto",
    "section": "The Linear Model",
    "text": "The Linear Model\nIn this section, we will walk through the process of fitting, comparing, and reporting hierarchical linear models in R. This is not a statistics tutorial, so there will be minimal detail about how to understand or interpret the output of these commands. Instead, refer to Prof Andy Field’s discovr tutorials, which are the primary teaching materials for the same content in UG teaching. All of the code and interpretation in the following section is from discovr_08, the GLM.\n\nThere are two key goals for this linear model walkthrough:\n\nCreate a detailed “cheatsheet” for a linear model analysis for future reference\nGet familiar with the discovr tutorials\n\nOf the two, the first is more important. I’d strongly recommend you open the relevant discovr tutorial and skim through it as you go so you’re familiar with what it contains. However, the following sections of this tutorial will present the same code and information with very abbreviated text, to serve as a quick reference.\nYou can also have them both open at once and refer to each!\n\n\n\n\n\n\n\nUsing the discovr tutorials\n\n\n\n\n\nProf Andy Field’s discovr tutorials provide detailed walkthroughs of both the R code and the statistical concepts of a variety of statistical analyses. They are a good place to look first to understand what your UG supervisees or advisees have been taught on a particular topic.\nThe tutorials are built in {learnr}, an interactive platform for learning and running R code. So, unlike the tutorial you’re currently reading, they must be run inside an R session. We have already installed all of the tutorials in your Posit Cloud workspace.\nTo open a tutorial, open any project and click on the Tutorial tab in the Environment pane. You can run any tutorial from here, but the relevant one for the linear modelling we are working on now is discovr_08, “the GLM”. Scroll down to this tutorial and click the “Start Tutorial ▶️” button to load the tutorial.\nBecause discovr tutorials run within R, you don’t need to use any external documents; you can write and run R code within the tutorial itself. However, I strongly recommend that whenever you work with these tutorials, you write and run your code in a separate document, otherwise you will have no record of the code and output.\n\n\n\n\nData and Codebook\nToday’s data is a truncated version of the TeachingRatings dataset from the {AER} package. You can load the codebook in the Help viewer by running the following in the Console:\n?AER::TeachingRatings\n\n\nOne Predictor\nNow that we have some data, we can fit our first model with a single predictor. We will do this with the very hardworking lm() function in R, standing for “linear model”.\nThe lm() function has a lot of options (as you might expect, given the versatility and ubiquity of linear models!), but its basic format to fit a linear model with a single predictor is very simple:\nlm(outcome ~ predictor, data = our_dataset)\nIn this function, outcome ~ predictor is a formula expressing a (simplified version of) the linear model equation. Here, outcome is the name of the variable in our_dataset that contains the outcome or dependent variable y, and predictor is the name of the variable that contains the predictor or independent variable x.\n\n\n\n\n\n\nExercise\n\n\n\nCreate a new code chunk and use the Codebook and the lm() function to fit a linear model predicting teaching evaluation score from beauty ratings. Save the resulting model in a new object called eval_lm.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\neval_lm &lt;- lm(eval ~ beauty, data = teach_tib)\n\nThat’s it!\n\n\n\n\n\n\nModel Information\nNow we have a new object that contains all the information about our model. We could simply call the name of this object, but the output doesn’t tell us anything besides the actual value of the b estimates. Instead, we’ll use some useful functions from the {tidyverse} package {broom} to get the information we need.\n\n\nModel Fit\nTo get some common measures of model fit, we can use the function broom::glance(). The output includes \\(R^2\\), adjusted \\(R^2\\), and F and accompanying statistics in comparison to the null model (the mean of the outcome alone).\n\n\n\n\n\n\nExercise\n\n\n\nIn a new code chunk, put the eval_lm object into broom::glance() to get model fit statistics.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nbroom::glance(eval_lm)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0357        0.0336 0.545      17.1 0.0000425     1  -375.  757.  769.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\n\n\n\nHelpfully, broom::glance() (and many other {tidyverse} functions) output tibbles, which means we can work with them as we already know how to do. In Tutorials 4 and 5, we’ll also learn more about changing and filtering tibbles that will make this very more useful. For now, we can simply note the information we get out of this function for future use.\n\n\nModel Parameters\nTo get information about the b estimates for individual predictors, we can use the function broom::tidy(). We could run this function without any other information, as we did with glance() above, but we’ll change one argument here in order to get 95% confidence intervals for b in the output as well.\n\n\n\n\n\n\nExercise\n\n\n\nIn a new code chunk, put the eval_lm object into broom::tidy(). Use the argument conf.int = TRUE to obtain confidence intervals.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nbroom::tidy(eval_lm, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term        estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    4.00     0.0253    158.   0           3.95       4.05 \n2 beauty         0.133    0.0322      4.13 0.0000425   0.0698     0.196\n\n\n\n\n\n\n\n\n\n\nHierarchial Models\nNext, we may want to test the addition of further predictors in the model. We can then compare the more complex multi-predictor model to the single-predictor model.\n\n\n\n\n\n\nExercise\n\n\n\nIn a new code chunk, fit a linear model with teaching evaluations as the outcome, and both beauty ratings and gender as predictors. Save the model output in a new object called eval_full_lm.\nThen, obtain model fit statistics and parameters as before.\nHint: to add a new predictor, you will need to literally add it (+) to the formula.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\neval_full_lm &lt;- lm(eval ~ beauty + gender, data = teach_tib)\n\nbroom::glance(eval_full_lm)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic     p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0663        0.0622 0.537      16.3 0.000000141     2  -368.  744.  760.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nbroom::tidy(eval_full_lm)\n\n# A tibble: 3 × 5\n  term         estimate std.error statistic    p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)     4.08     0.0329    124.   0         \n2 beauty          0.149    0.0320      4.65 0.00000434\n3 genderfemale   -0.198    0.0510     -3.88 0.000120  \n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat About Interactions?\n\n\n\n\n\nThe models we’re describing here contain only additions, not interactions. So, you may be wondering, “What if I want to model more complex relationships between predictors?” If that’s what you’re trying to do now, you may want to jump ahead to discovr_10 for moderation and mediation.\nOtherwise, we will get there in this course eventually!\n\n\n\n\nComparing Models\nNow we have two models, one simpler with only a single predictor, and the other with two predictors. We might next want to test whether the more complex, two-predictor model is a significant improvement over the simpler model, in order to decide which model to retain. We can do this with the anova() function1 to compare the two models.\n\n\n\n\n\n\nWarning\n\n\n\nThe anova() function will only work for model comparison for particular models.\n\nThe models must be hierarchical. That is, the more complex model(s) must contain all of the predictor(s) present in the less complex model(s).\nAll models must be fit to the same dataset. If, for example, your first predictor has no missing values, but your second predictor had one, the model with using the second predictor would have been fit to a dataset of a different size than the model using only the first, and the anova() function will throw an error to this effect.\n\nIf you encounter this issue, you may need to inspect and clean your dataset before you proceed with analysis!\n\n\n\n\n\n\n\n\nExercise\n\n\n\nPut both model objects into the anova() function to find out which model to retain.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nanova(eval_lm, eval_full_lm)\n\nAnalysis of Variance Table\n\nModel 1: eval ~ beauty\nModel 2: eval ~ beauty + gender\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    461 137.16                                  \n2    460 132.81  1    4.3467 15.056 0.0001196 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nSignificance Codes\n\n\n\n\n\nThe output from many base-R {stats} functions, like anova(), include a line labeled Signif. codes that provide a key for understanding the notation given for significance levels in p-values.\nReading the key from left to right, we can see that a result is given three asterisks (***) when the p-value is between 0 and .001; two asterisks between .001 and .01; and so on.\nThis can be a useful visual check, especially because p-values that are very, very small are frequently expressed in scientific notation, which can make them more difficult to spot.\n\n\n\nThe F-test is significant, indicating that the more complex two-predictor model is a significant improvement over the one-predictor model, so we will proceed with the two-predictor model.\n\n\nStandardised Bs\nYou may have noticed that the output we’ve seen so for only contains unstandardised model parameter estimates. If we want standardised Bs expressing the relationship between predictor(s) and outcome in standard deviation units, we can make use of the model_parameters() function from the {parameters} package to standardise our bs.\n\n\n\n\n\n\nExercise\n\n\n\nUse the standarize = \"refit\" argument in the parameters::model_parameters() function to obtain standardised Bs.\n\n\n\n\n\n\nWarning\n\n\n\nNote the spelling of standardize with a “z”! Spelling it with an “s” will not rescale the parameter estimates.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nparameters::model_parameters(eval_full_lm, standardize = \"refit\")\n\nParameter       | Coefficient |   SE |         95% CI | t(460) |      p\n-----------------------------------------------------------------------\n(Intercept)     |        0.15 | 0.06 | [ 0.03,  0.27] |   2.53 | 0.012 \nbeauty          |        0.21 | 0.05 | [ 0.12,  0.30] |   4.65 | &lt; .001\ngender [female] |       -0.36 | 0.09 | [-0.54, -0.18] |  -3.88 | &lt; .001\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation.\n\n\n\n\n\n\n\n\n\n\nAssumptions Checks\nAt Sussex, we teach a range of model diagnostics and robust model sensitivity tests in order to test model assumptions. We will look briefly at each of these in turn.\n\n\n\n\n\n\nTip\n\n\n\nRemember, there are more examples and longer explanations in the discovr_08 tutorial!\n\n\n\nResidual Plots\nTo begin, we can generate nicely formatted, customisable residual plots using the function ggplot2::autoplot(). However, it is essential to load the {ggfortify} package in order for this to work!\n\n\n\n\n\n\nExercise\n\n\n\nLoad the {ggfortify} package and use the autoplot() function to generate residual plots for eval_full_lm. Set the which argument to c(1, 3, 2, 4).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(ggfortify)\n\nWarning: package 'ggfortify' was built under R version 4.3.1\n\n\nLoading required package: ggplot2\n\n\nWarning: package 'ggplot2' was built under R version 4.3.1\n\nggplot2::autoplot(eval_full_lm, which = c(1, 3, 2, 4))\n\n\n\n\nIf you’re wondering what’s up with which, the plot() function that autoplot() is based on has a total of six plots available. Here I’ve chosen the two residual plots, the normal Q-Q and the Cook’s distance plot. Plots 5 and 6 have to do with leverage, which we don’t teach at UG level. To see them, simply add them to the which = argument.\n\n\n\n\n\nIf you want to customise the theme or look of these plots further, they are built with {ggplot2} so you can add or change anything about them using that package. We will come round later to a detailed exploration of data visualisations with {ggplot2}.\n\n\nDistribution of Standardised Residuals\nIn the UG core statistics modules at Sussex, we teach that normality is the least important of the assumptions of the linear model - the most important being additivity and linearity - so we do not generally worry too much about normally distributed standardised residuals, especially in large sample sizes. However, we do teach them how to evaluate the proportion of standardised residuals with values above ±1.96 (approximately 5%), ±2.56 (approximately 1%), and above ±3 (likely an outlier). For details on how to use broom::augment() to obtain standardised residuals and other model diagnostic measures like Cook’s distance, see the discovr_08 tutorial.\n\n\nRobust Models\nAt UG level, we teach robust models for two purposes:\n\nAs sensitivity tests to check assumptions. If a robust technique that adjusts for a particular issue, such as heteroscedasticity, results in a model that is substantially different from the unadjusted model, we might conclude that the unadjusted model did in fact have that particular issue.\nAs robust alternatives to the unadjusted model.\n\n\nRobust Parameter Estimates\nOur first robust model re-estimates the parameter estimates using robust techniques withe the robust::lmRob() function. We can then compare the robust parameter estimates to the unadjusted ones obtained with lm() to find out if our estimates were biased, and report the robust parameter estimates if they were.\n\n\n\n\n\n\nExercise\n\n\n\nFit the same two-predictor model again with robust::lmRob() and compare the results to the unadjusted two-predictor model.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\neval_lm_rob &lt;- robust::lmRob(eval ~ beauty + gender, data = teach_tib)\n\neval_lm_rob\n\n\nCall:\nrobust::lmRob(formula = eval ~ beauty + gender, data = teach_tib)\n\nCoefficients:\n (Intercept)        beauty  genderfemale  \n      4.1044        0.1388       -0.2071  \n\neval_full_lm\n\n\nCall:\nlm(formula = eval ~ beauty + gender, data = teach_tib)\n\nCoefficients:\n (Intercept)        beauty  genderfemale  \n      4.0816        0.1486       -0.1978  \n\n\nComparing the values of the two versions of the model, we can see that the parameter estimates have changed very little, so we might conclude that the unadjusted model was fine.\n\n\n\n\n\n\n\nRobust CIs and p-values\nTo test and adjust for heteroscedastic residuals, we can re-estimate the standard error using a robust method. To do this, we’ll use the parameters::model_parameters() function with the argument vcov = \"HC4\" as recommended in the discovr tutorial. To do this, use the unadjusted model object eval_full_lm as the first argument.\n\n\n\n\n\n\nExercise\n\n\n\nUse parameters::model_parameters() to re-estimate the SEs, CIs, and p-values, and compare the results to the unadjusted model.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nparameters::model_parameters(eval_full_lm, vcov = \"HC4\")\n\nParameter       | Coefficient |   SE |         95% CI | t(460) |      p\n-----------------------------------------------------------------------\n(Intercept)     |        4.08 | 0.03 | [ 4.02,  4.15] | 125.28 | &lt; .001\nbeauty          |        0.15 | 0.03 | [ 0.08,  0.21] |   4.59 | &lt; .001\ngender [female] |       -0.20 | 0.05 | [-0.30, -0.10] |  -3.94 | &lt; .001\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation.\n\nbroom::tidy(eval_full_lm, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term         estimate std.error statistic    p.value conf.low conf.high\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     4.08     0.0329    124.   0            4.02      4.15  \n2 beauty          0.149    0.0320      4.65 0.00000434   0.0858    0.211 \n3 genderfemale   -0.198    0.0510     -3.88 0.000120    -0.298    -0.0976\n\n\nThe parameter estimates will not change, but the SEs, CIs, and p-values may. Here, the values are nearly identical and there are no major changes - that is, no predictors have become non-significant that were previously significant - so we might again conclude that the unadjusted model was not unduly biased.\n\n\n\n\n\n\n\nBootstrapping\nIf we had a small sample size, a final option would be to bootstrap the confidence intervals. To do this, we will again use parameters::model_parameters(), but this time with bootstrap = TRUE.\nNote: Sample size is not an issue with this dataset (N = 463).\n\n\n\n\n\n\nExercise\n\n\n\nProduce bootstrapped confidence intervals for the two-predictor model and compare to the unadjusted confidence intervals.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nparameters::model_parameters(eval_full_lm, bootstrap = TRUE)\n\nParameter       | Coefficient |         95% CI |      p\n-------------------------------------------------------\n(Intercept)     |        4.08 | [ 4.02,  4.15] | &lt; .001\nbeauty          |        0.15 | [ 0.08,  0.21] | &lt; .001\ngender [female] |       -0.20 | [-0.30, -0.09] | &lt; .001\n\n\n\nUncertainty intervals (equal-tailed) are naıve bootstrap intervals.\n\nbroom::tidy(eval_full_lm, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term         estimate std.error statistic    p.value conf.low conf.high\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     4.08     0.0329    124.   0            4.02      4.15  \n2 beauty          0.149    0.0320      4.65 0.00000434   0.0858    0.211 \n3 genderfemale   -0.198    0.0510     -3.88 0.000120    -0.298    -0.0976\n\n\nWe could once again note that there are no major changes, as previously, so the evidence of our checks suggests that the original, unadjusted model was not unduly biased."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/04_lm.html#quarto",
    "href": "tutorials/psychrlogy/01_fundRmentals/04_lm.html#quarto",
    "title": "04: Reporting Linear Models with Quarto",
    "section": "Quarto",
    "text": "Quarto\nQuarto documents are a mix of text and code, the next generation of R Markdown documents. For our purposes, we will be using R within Quarto, but Quarto documents support the integration of many different coding languages, including Python, Julia, and Observable. If you’ve previously used Rmd (RMarkdown), Quarto is backwards-compatible and will able to render most documents with no issues.\n\n\n\n\n\n\nHelp with Quarto\n\n\n\nThe official Quarto Guide is extensive, detailed, and extremely helpful. It’s always the best first stop for any questions you have about using Quarto. Quarto also offers detailed tutorials.\nThis quick-reference to Markdown formatting is particularly helpful.\nProf Andy Field has also recorded a series of video guides to using Quarto that are used in UG teaching.\n\n\n\nGetting Started\nTo get some hands-on practice working with Quarto, we will create a new Quarto document from scratch. We will use the analysis code we’ve already written to create a nicely formatted report.\n\n\n\n\n\n\nExercise\n\n\n\nCreate a new Quarto document via File &gt; New File &gt; Quarto Document.\nIf you like, you can give it a title; you will be able to change this later.\nThen, click “Create”.\n\n\nBy default, your new Quarto document will already have some settings and content to demonstrate how it works. Most importantly, you can see that there are three main types of information in this document:\n\nThe YAML header at the top, delineated by ---s, which contains information about how the document will be rendered\nThe body text, which contains regular (i.e. non-code) text\nThe code chunks, which contain code - in this case, specifically, R.\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTo complete our setup, take the following steps:\n\nDelete everything in the new Quarto document except for the YAML header (i.e. all the text and code chunks).\nClear your Environment by clicking the broom icon in the Environment tab.\nRestart your R session (via Session &gt; Restart R).\n\n\n\n\n\n\n\nWarning\n\n\n\nMake sure you have completed and saved your worksheet with all of your code before you do this!\n\n\n\n\n\n\n\n\n\n\nVisual vs Source Mode\n\n\n\n\n\nA new feature with Quarto is Visual mode, which is very like using Word or a similar word processing programme. All formatting can be applied and previewed in the document itself, using keyboard shortcuts or the familiar formatting buttons along the top toolbar.\nVisual mode also has an “insert anything” shortcut, /, that allows you to quickly insert elements into your document. If you type / at the start of a new line (or Ctrl/Cmd + / otherwise), a drop-down list of possible elements will appear, which you can navigate by scrolling or search by typing.\nAlternatively, you can toggle to Source mode by clicking the “Source” button at the very top left of the document pane. In Source mode you can edit the document using Markdown formatting. This allows more fine-tuned control of elements, but automatic formatting and the / shortcut don’t work in this mode.\nWhich you use is entirely personal preference - I toggle regularly between them depending on what I’m trying to do, so pick whichever works for you.\n\n\n\n\n\nCreating a Code Chunk\nTo prepare for our analysis, we will need a place to load packages and read in the data. Any executable code - that is, code that you want to run and do something - must be written in a code chunk and NOT in the body text2.\n\n\n\n\n\n\nInserting Code Chunks\n\n\n\nThere are several ways to insert a new code chunk.\n\nIn Visual mode, by typing / and then Enter (since “R Code Chunk” is the first option)\nIn either mode, by:\n\nClicking the green “insert code chunk” button in the top right\nTyping out the literal code fencing: ```{r} ```\nUsing a keyboard shortcut.\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCreate a new code chunk and code that does the following:\n\nLoad all the packages we used in the previous Linear Model section\nRead in the dataset located in the data folder of your project into an object called teach_tib\nCreate the two objects containing the linear models with one predictor and with two predictors.\n\nThen, run the code chunk.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLoad packages:\nIn the previous section, we used the following packages:\n\n{tidyverse}, or specifically {broom}, for tidying up the linear model output\n{ggfortify} for creating diagnostic plots\n{parameters} for standardising bs, re-estimating CIs, and boostrapping\n{robust} for robust parameter estimates\n\nRead in the data:\nIn the Posit Cloud project workspace for this tutorial, there is a teaching.csv object. Look back on Tutorial 02 for more detail about how to read in datasets.\nCreate the models:\nCopy and paste the code from your workbook document, or from the previous sections of this tutorial. You can also find all of the commands you have run your History tab (next to Environment).\nAltogether, your new code chunk should look like this:\n```{r}\nlibrary(tidyverse)\nlibrary(ggfortify)\nlibrary(parameters)\nlibrary(robust)\n\nteach_tib &lt;- readr::read_csv(\"data/teaching_ratings.csv\")\n\neval_lm &lt;- lm(eval ~ beauty, data = teach_tib)\neval_full_lm &lt;- lm(eval ~ beauty + gender, data = teach_tib)\n```\nRun the code chunk by clicking the green “play” arrow, or by pressing Ctrl/Cmd + Shift + Enter while your cursor is inside the chunk.\n\n\n\n\n\n\n\nHeadings and Text\n\nHeadings\nTo begin, we’ll use headings to map out our document. Properly formatted headings are strongly recommended for any documents you write, for a variety of reasons:\n\nThey automatically create the outline (to the right) and navigation menu (to the bottom) of your document for easy navigation\nThey can be automatically converted into a table of contents\nThey are a crucial accessibility feature for navigating the document via keyboard/screenreader, as well as providing clear visual structure.\n\n\n\n\n\n\n\nInserting Headings\n\n\n\nThere are several ways to insert a new heading.\n\nIn Visual mode, by:\n\nUsing the text formatting dropdown. Click on “Normal” and select the heading level.\nUsing a keyboard shortcut, Ctrl + Alt + the number of the heading (e.g. 3 for a level 3 heading)\n\nIn either mode, by:\n\nTyping hashes at the start of a new line, followed by a space (e.g. ### creates a level 3 heading)\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCreate 2-3 level 2 headings in your document for the brief report of the linear model. You can choose anything you like, but the three I will refer to will be called “Model Comparison” (constructing and comparing the two models), “Assumptions Checks”, and “The Final Model” (reporting the final model in full).\n\n\n\n\nBody Text\nAny new-line text will automatically be plain text. This can be anything you like, although in our current document, we are writing a mock-formal results section.\n\n\n\n\n\n\nFormatting Text\n\n\n\nHow to format body text depends on the mode you are in.\n\nIn Visual mode, by:\n\nUsing familiar keyboard shortcuts (e.g. Ctrl/Cmd + B for bold, Ctrl/Cmd + I for italics, etc.)\nUsing the formatting toolbar at the top of the document.\n\nIn Source mode, by using Markdown formatting.\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUnder the first heading (which I have called “Model Comparison”), write a brief, journal-style description of the variables the two models contain.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf you aren’t inclined to write your own, here’s a brief sample text to use.\n\nTwo linear models were constructed to investigate the influences on teaching evaluation ratings. The first model contained only instructor beauty ratings as a predictor, and teaching evaluation ratings as the outcome (R2 = ???, F(???, ???) = ???, p = ???). The second model added instructor gender as a second predictor with no interaction, both again predicting teaching evaluation ratings (R2 = ???, F(???, ???) = ???, p = ???). An ANOVA comparing the models indicated a significant improvement in model fit for the second model compared to the first (F(???, ???) = ???, p = ???).\n\n\n\n\n\n\n\n\n\nDynamic Reporting\nThat last sentence should report which of the two models was better, based on the result of our F-test, rather than question marks. We could produce the output of this test, read it ourselves with our very own eyes/ears, and then type out the results by hand…but that is definitely not what we are going to do! Instead, we’ll look at a couple options for reporting the results dynamically. (We’ll come back to the model R2s in a moment.)\n\nInline Code\nOur first option is to use inline code to report the numbers. In order to do this, we first need to know what information we have available in the test output, so we can make use of it.\n\n\n\n\n\n\nTip\n\n\n\nThis section will make extensive use of $ subsetting, which was covered in Tutorial 02, and [] subsetting, which was covered in Tutorial 01.\n\n\n\n\n\n\n\n\nExercise\n\n\n\nIn a new code chunk, use the broom::tidy() function to get a nice tibble of the anova() comparison between the two models, and save it in a new object called tidy_f. Then, print out this object in the Console.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are creating the tidy_f object in a code chunk because we will want to use it again in our report.\nWe are calling this object in the Console because viewing its contents is only for our information/reference, and not something we want to appear or use directly in our finished document.\n\n## In a code chunk\ntidy_f &lt;- broom::tidy(anova(eval_lm, eval_full_lm))\n\n## In the Console\ntidy_f\n\n# A tibble: 2 × 7\n  term                   df.residual   rss    df sumsq statistic   p.value\n  &lt;chr&gt;                        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 eval ~ beauty                  461  137.    NA NA         NA   NA       \n2 eval ~ beauty + gender         460  133.     1  4.35      15.1  0.000120\n\n\n\n\n\n\n\nThe tibble we get here is quite different from the “Analysis of Variance Table” text output that we saw earlier when we printed out the results of the anova() function on its own. We now have all the values we need to report these results in a conveniently subsettable tibble with nice R-friendly names.\nSo, let’s have a go getting at some of those values.\n\n\n\n\n\n\nExercise\n\n\n\nGet out the F-ratio of 15.0554899 from this object, and round it to two decimal places.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst, we need to get out the statistic variable, which we can do with $.\n\ntidy_f$statistic\n\n[1]       NA 15.05549\n\n\nThis returns a vector of two values, NA and 15.0554899. To index the second of these values, we need [] subsetting and the index number of the correct value.\n\ntidy_f$statistic[2]\n\n[1] 15.05549\n\n\nFinally, we can use the round() function to round to two decimal places.\n\nround(tidy_f$statistic[2], 2)\n\n[1] 15.06\n\n\n\n\n\n\n\nWe now have a bit of R code that produces a single number that we want to report in the text3. The issue is that code chunks contain code, and body text contains text, but we would like the code that we’ve written to print out its value in the text!\nThe solution is inline code, a small bit of R code written in the body text (“inline”) that will, when the document is rendered, automatically insert the right number. Inline code is written as follows, in the text: `r some_r_code`\nFor our reporting, we will need to insert the inline code in exactly the spot where we would like the output of the code to appear. This particular bit of code produces the F-statistic, so we can replace the “???”s in our reporting where the value of the F-statistic should go:\n\nAn ANOVA comparing the models indicated a significant improvement in model fit for the second model compared to the first (F(???, ???) = `r round(tidy_f$statistic[2], 2)`, p = ???).\n\nYou can check whether this has worked in two ways:\n\nPlace your cursor inside the backticks and press Ctrl/Cmd + Enter, as you would inside a code chunk. This will run the code and a small pop-up will show you what that code will produce when rendered.\nRender your document and see what appears!\n\n\n\n\n\n\n\nExercise\n\n\n\nUse inline code to replace all of the ???s in the F-test reporting to produce a final report in APA style.\nHint: Rounding p-values is a bit tricky. Check out the {papaja} package to see if you can find a function besides round() that will produce the p-value with the correct formatting.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAll of the other numbers should be straightforward, except for the p-value. Rounding to three decimal places with round() will result in a value of 0, which is not what we want. Instead, since the p-value is below .001, we want “&lt; .001”.\n{papaja} has the printp() function, which will do this exactly was we like (as well as containing a lot of other useful functions for rounding and printing in APA style!)\nYour final text may look like this:\n\nAn ANOVA comparing the models indicated a significant improvement in model fit for the second model compared to the first (F(`r tidy_f$df[2]`, `r tidy_f$df.residual[2]`) = `r round(tidy_f$statistic[2], 2)`, p `r papaja::printp(tidy_f$p.value[2]`).\n\nNote that there’s no need for a “&lt;” symbol because papaja::printp() includes it automatically.\nThis will render as:\n\nAn ANOVA comparing the models indicated a significant improvement in model fit for the second model compared to the first (F(1, 460) = 15.06, p &lt; .001).\n\n\n\n\nCHALLENGE: Create a bit of inline code that will either report a significant or non-significant result depending on the value of p.\nHint: You may need to check out the ifelse() function.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf we really want our reporting to be resilient, we want to remove or replace all the places where we have to manually remember to update the code if our results change. In this case, our reporting reads:\n\nAn ANOVA comparing the models indicated a significant improvement in model fit…\n\nBut if we wanted to reuse this code for another report, we would have to remember to update this depending on the actual value of p. OR, we can have R do it for us.\nFirst, we need to write a bit of R code that will evaluate whether the value of p is above or below a particular threshold, and then output the correct text. We could do this with ifelse(), a handy little base R function with three arguments. The first is a test returning a logical value (either TRUE or FALSE). If the test returns TRUE, the second argument is executed; if the test returns FALSE, the final argument is executed.\n\nifelse(\n1  tidy_f$p.value[2] &lt; .05,\n2  \"significant\",\n3  \"non-significant\"\n)\n\n\n1\n\nThe test: is the p-value for our F-test less than .05? (If you have a different \\(\\alpha\\)-threshold, you could hard-code it here or use an object you’ve defined previously for this comparison.)\n\n2\n\nWhat to do if the test returns TRUE: print “significant”.\n\n3\n\nWhat to do if the test returns FALSE: print “non-significant”.\n\n\n\n\n[1] \"significant\"\n\n\nWe can then take this command and replace the word “significant” in our report with this inline code:\n\nAn ANOVA comparing the models indicated a `r ifelse(tidy_f$p.value[2] &lt; .05, \"significant\", \"non-significant\")` improvement in model fit…\n\nNow we don’t have to worry about getting this right: our document, when rendered, will automatically insert the right word depending on the data.\n\n\n\n\n\n\n\nAutomatic Reporting\nAs helpful as inline code is (and I would recommend reporting all values dynamically/automatically wherever possible, so it is very useful!), you may have noticed that there was a lot of repetitive typing that also made the text itself quite difficult to read, as well lots of opportunities make typos or mistakes. Surely there’s a simpler way to do this sort of thing!\nThere are, in fact, many simpler ways to do common tasks like this, which take advantage of the fact that an object created by a particular function will always have the same structure. One option is to make further use of the {papaja} package, which is designed for just this purpose.\n\n\n\n\n\n\nExercise\n\n\n\nUse the {papaja} documentation to fill in the statistical reporting for each of the linear models (i.e., R2, F, and p) using only one piece of inline code for each.\nWhen you’re done, render your document to see the results!\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe {papaja} documentation illustrates the process using t.test(), which works the same way as lm(). The key here is to use the original objects containing the models you want to report.\nLet’s have a look at the first of the two models and see what the papaja::apa_print() function gives us.\n\npapaja::apa_print(eval_lm)\n\n$estimate\n$estimate$Intercept\n[1] \"$b = 4.00$, 95\\\\% CI $[3.95, 4.05]$\"\n\n$estimate$beauty\n[1] \"$b = 0.13$, 95\\\\% CI $[0.07, 0.20]$\"\n\n$estimate$modelfit\n$estimate$modelfit$r2\n[1] \"$R^2 = .04$\"\n\n$estimate$modelfit$r2_adj\n[1] \"$R^2_{adj} = .03$\"\n\n$estimate$modelfit$aic\n[1] \"$\\\\mathrm{AIC} = 756.65$\"\n\n$estimate$modelfit$bic\n[1] \"$\\\\mathrm{BIC} = 769.06$\"\n\n\n\n$statistic\n$statistic$Intercept\n[1] \"$t(461) = 157.73$, $p &lt; .001$\"\n\n$statistic$beauty\n[1] \"$t(461) = 4.13$, $p &lt; .001$\"\n\n$statistic$modelfit\n$statistic$modelfit$r2\n[1] \"$F(1, 461) = 17.08$, $p &lt; .001$\"\n\n\n\n$full_result\n$full_result$Intercept\n[1] \"$b = 4.00$, 95\\\\% CI $[3.95, 4.05]$, $t(461) = 157.73$, $p &lt; .001$\"\n\n$full_result$beauty\n[1] \"$b = 0.13$, 95\\\\% CI $[0.07, 0.20]$, $t(461) = 4.13$, $p &lt; .001$\"\n\n$full_result$modelfit\n$full_result$modelfit$r2\n[1] \"$R^2 = .04$, $F(1, 461) = 17.08$, $p &lt; .001$\"\n\n\n\n$table\nA data.frame with 6 labelled columns:\n\n       term estimate     conf.int statistic  df p.value\n1 Intercept     4.00 [3.95, 4.05]    157.73 461  &lt; .001\n2    Beauty     0.13 [0.07, 0.20]      4.13 461  &lt; .001\n\nterm     : Predictor \nestimate : $b$ \nconf.int : 95\\\\% CI \nstatistic: $t$ \ndf       : $\\\\mathit{df}$ \np.value  : $p$ \nattr(,\"class\")\n[1] \"apa_results\" \"list\"       \n\n\nWe’ve got a huge number of options here, but for this exercise we wanted R2, F, and p. All three are given under $full_result$modelfit$r2. We will need to save the output from apa_print() into an object, then we can subset it using inline code:\n\neval_lm_out &lt;- papaja::apa_print(eval_lm)\neval_full_lm_out &lt;- papaja::apa_print(eval_full_lm)\n\n\nTwo linear models were constructed to investigate the influences on teaching evaluation ratings. The first model contained only instructor beauty ratings as a predictor, and teaching evaluation ratings as the outcome (`r eval_lm_out$full_result$modelfit$r2`). The second model added instructor gender as a second predictor with no interaction, both again predicting teaching evaluation ratings (`r eval_full_lm_out$full_result$modelfit$r2`).\n\nWhich will render as:\n\nTwo linear models were constructed to investigate the influences on teaching evaluation ratings. The first model contained only instructor beauty ratings as a predictor, and teaching evaluation ratings as the outcome (\\(R^2 = .04\\), \\(F(1, 461) = 17.08\\), \\(p &lt; .001\\)). The second model added instructor gender as a second predictor with no interaction, both again predicting teaching evaluation ratings (\\(R^2 = .07\\), \\(F(2, 460) = 16.33\\), \\(p &lt; .001\\)).\n\n\n\n\n\n\n\n\nTable Formatting\nNext, we will jump to the “Final Model” heading and have a look at how to turn our final model output into a nicely formatted table. Once again, {papaja} provides a quick and beautiful solution for reporting, so let’s use it again.\n\n\n\n\n\n\nExercise\n\n\n\nUsing the {papaja} help documentation, produce a nicely formatted table of the final model, presenting the parameter estimates, p-values etc. for each predictor under the third (“Final Model”) heading.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe already have the necessary object, eval_full_lm_out, from the previous task. We just need to subset it as described in the help documentation.\nThis command should go in a new code chunk, wherever you want the table to appear in your document.\n\npapaja::apa_table(eval_full_lm_out$table)\n\n\n(#tab:unnamed-chunk-19)\n\n\n**\n\n\n\n\nPredictor\n\\(b\\)\n95% CI\n\\(t\\)\n\\(\\mathit{df}\\)\n\\(p\\)\n\n\n\n\nIntercept\n4.08\n[4.02, 4.15]\n123.94\n460\n&lt; .001\n\n\nBeauty\n0.15\n[0.09, 0.21]\n4.65\n460\n&lt; .001\n\n\nGenderfemale\n-0.20\n[-0.30, -0.10]\n-3.88\n460\n&lt; .001\n\n\n\n\n\n\n\n\nCHALLENGE: {papaja} isn’t the only package to provide easy formatting for commonly reported tests. Have a go creating this table again using the nice_table() function from the {rempsyc} package, which allows a bit more flexibility in\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe nice_table() function can be for tables generally, but it can apply specialised formatting for model tables created with broom, if we use the broom = argument to tell the function what formatting template to apply.\n\nrempsyc::nice_table(broom::tidy(eval_full_lm, conf.int = TRUE), broom = \"lm\")\n\n\nTermbSEtp95% CI(Intercept)4.080.03123.94&lt; .001***[4.02, 4.15]beauty0.150.034.65&lt; .001***[0.09, 0.21]genderfemale-0.200.05-3.88&lt; .001***[-0.30, -0.10]\n\n\n\n\n\n\n\n\n\nCross-Referencing\nAs anyone who has had to create a long document with lots of tables and figures knows, keeping track of the numbering is a huge pain, especially when, for instance, a reviewer asks you to add something partway through and then everything has to be renumbered.\nThe good news is that Quarto can take care of figure and table numbering automatically. There are two steps to this:\n\nInclude a label in the relevant code chunk, using the prefix fig- for figures and tbl- for tables.\nRefer to the figure or table in the text using @.\n\n\n\n\n\n\n\nExercises\n\n\n\nUsing the Quarto help documentation, write a short introductory sentence under the “Final Model” heading and refer to the final model table with a cross-reference.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst, add a label and caption to the code chunk from the previous task that produces the model table.\n```{r}\n#| label: tbl-final-model\n#| tbl-cap: \"The final model predicting teaching evaluation ratings from instructor beauty and gender.\"\n\npapaja::apa_table(eval_full_lm_out$table,\n                  caption = \"The final model predicting teaching evaluation ratings from instructor beauty and gender.\")\n```\nYou can of course write whatever you like, or borrow the text below, but use “Table 1” (or whatever label your gave the table code chunk) to refer to the table.\n\nThe final model with two predictors is presented in full in @tbl-final-model.\n\nAltogether, it should render as follows:\n\nThe Final Model\nThe final model with two predictors is presented in full in Table 1.\n\n\npapaja::apa_table(eval_full_lm_out$table)\n\n\n(#tab:tbl-final-model)\n\n\n**\n\n\n\nTable 1: The final model predicting teaching evaluation ratings from instructor beauty and gender.\n\n\nPredictor\n\\(b\\)\n95% CI\n\\(t\\)\n\\(\\mathit{df}\\)\n\\(p\\)\n\n\n\n\nIntercept\n4.08\n[4.02, 4.15]\n123.94\n460\n&lt; .001\n\n\nBeauty\n0.15\n[0.09, 0.21]\n4.65\n460\n&lt; .001\n\n\nGenderfemale\n-0.20\n[-0.30, -0.10]\n-3.88\n460\n&lt; .001\n\n\n\n\n\n\n\n\n\nCHALLENGE: Complete the final “Assumptions Checks” section summarising the checks and using figure cross-referencing to insert and refer to the diagnostic plots.\nHint: To report the exact maximum value of Cook’s distance, you will also need to refer to discovr_08 for how to use broom::augment().\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou can write whatever you like, but here’s a suggestion with the plot included.\n\nAssumptions Checks\nWe next assessed the model with two predictors for any evidence of bias. Residual plots (@fig-diag-plots) did not indicate any outstanding issues with normality, linearity, or heteroscedasticity. There was also no evidence of influential cases, as the max value of Cook’s distance was `r round(max(broom::augment(eval_full_lm)$.cooksd), 2)`. Robust models were also fitted as sensitivity checks. Robust parameter estimates estimated using the {robust} package were minimally different from the unadjusted parameter estimates. Similarly, robust HC4 standard errors estimated using the {parameters} package yielded confidence intervals and p-values very similar to the unadjusted values. Therefore, we will proceed with the unadjusted two-predictor model as our final model.\n\n```{r}\n#| label: fig-diag-plots\n#| fig-cap: \"Diagnostic plots for the two-predictor model.\"\n\nggplot2::autoplot(eval_full_lm, which = c(1, 3, 2, 4))\n```\n\n\n\n\n\n\n\n\nRendering\nAfter all this work to analyse, interpret, and report, it’s finally time to produce the final document. The process of turning a Quarto document into some output format - including running all the code and applying all the formatting - is called rendering (previously knitting with RMarkdown).\n\n\n\n\n\n\nExercise\n\n\n\nRender your report document using the “Render” button at the top of the document, or by using the keyboard shortcut Ctrl/Cmd + Shift + K4.\n\n\n\nGlobal Options\nAt the moment, your report may not be as clean as we’d like it to be: there are likely messages from R floating around and code all over the place, whereas for a formal report, we of course only want to show the final output. This is where the YAML header comes in.\nThe default YAML header contains only a few explicit settings, and if you haven’t changed anything, probably looks like this:\n---\ntitle: \"Untitled\"\nformat: html\neditor: visual\n---\nBy adding options to the YAML header, we can determine how the document as a whole is rendered. Here are the common ones that I use on the regular:\n\n---\ntitle: \"Linear Model Report\"\nformat:\n  html:\n1    toc: true\neditor: visual\n2self-contained: true\n3execute:\n4  echo: false\n5  warning: false\n6  message: false\n---\n\n\n1\n\nAutomatically produce a table of contents (ToC) from the document headings.\n\n2\n\nCombine all the files, images, stylesheets etc. into a single output document. Necessary if you want to send an HTML file to someone else and have it look as it should!\n\n3\n\nSet default behaviour for all code chunks as follows\n\n4\n\nRun code and show output, but do not show the code itself.\n\n5\n\nDo not show any warnings produced by code.\n\n6\n\nDo not show any messages produced by code.\n\n\n\n\nThe requirements for each document will change depending on its purpose, so you will likely find that\n\n\n\n\n\n\nTip\n\n\n\nThe Quarto help documentation, as usual, has a complete list of YAML options, including how to set default behaviour for figures and other settings.\n\n\n\n\nCode Chunk Options\nGlobal options apply to the entire document, but you may want to change these settings for individual code chunks to override the default settings in the YAML.\nFor example, you may have a code chunk containing some processing code that you used to view and clean your data. If your global execution option is set to echo: false, the code output would still appear, although the code itself would be hidden. If, for this particular code chunk, you don’t want the output to appear either, you can override the global option with a local option for that chunk only.\nLocal code chunk options appear as “hashpipe” (#|) comments, as we have seen earlier with labels. They use the same syntax as YAML, but the settings only apply to individual code chunks. Any settings that aren’t explicitly changed within the chunk are inherited from the YAML settings.\nFor this example, we could set a local code chunk option include: false which will prevent the output from appearing in the document.5\n```{r}\n#| include: false\n\nsome_code_doing_cleaning_and_processing\n```\n\n\nOutput Formats\nFor these tutorials, we will generally stick to HTML, as it’s the most painless of the rendering options. However, you will likely find yourself wanting to produce some other type of document, which you can easily6 do from the same Quarto document.\nTo render to a different format, change the YAML format: setting to a different output.\n\n\n\n\n\n\nTip\n\n\n\nAs per, the Quarto guide on output formats has all the information you need!\n\n\n\n\n\n\n\n\nExercise\n\n\n\nRender your linear model report to a Word document.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimply update the format: html YAML option to format: docx and render your document. Note that the format options are usually named after the file extension rather than the name of the programme necessarily."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/04_lm.html#well-done",
    "href": "tutorials/psychrlogy/01_fundRmentals/04_lm.html#well-done",
    "title": "04: Reporting Linear Models with Quarto",
    "section": "Well done!",
    "text": "Well done!\nAnd there we have it! You now have a complete example of a linear model report, rendered into both HTML and Word, to refer to. It’s amazing how much you’re able to do after just a few weeks!\nThis is the end of the FundRmentals section of the course. If you’re so inclined, we’ll see you in the Essentials section, which will cover data wrangling and cleaning, and running and reporting many more statistical analyses."
  },
  {
    "objectID": "tutorials/psychrlogy/01_fundRmentals/04_lm.html#footnotes",
    "href": "tutorials/psychrlogy/01_fundRmentals/04_lm.html#footnotes",
    "title": "04: Reporting Linear Models with Quarto",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSomewhat confusingly, this is not the function we teach UGs to perform ANOVAs! See discovr tutorials 11, 12, 15, and 16 for a detailed guide through the afex package for running linear models with categorical predictors.↩︎\nMostly true, except for inline code!↩︎\nGenerally, inline code should only ever produce a single value, otherwise the formatting can get interesting. This value, however, could longer than a single number, if you want to get creative with your dynamic reporting!↩︎\nIt seems obvious that this should be R instead of K, but remember this made perfect sense when it was called “knitting”!↩︎\nFor writing tutorials, I make extensive use of eval: false, which includes the code in the output but does not attempt to run the code. This allows me to write all kinds of nonsense code without R getting stroppy and throwing errors all of the place!↩︎\nDepends crucially on what you consider to be “easy”, especially when dealing with PDFs!↩︎"
  },
  {
    "objectID": "tutorials/psychrlogy/02_essentials/05_dataviz.html",
    "href": "tutorials/psychrlogy/02_essentials/05_dataviz.html",
    "title": "05: Visualisations",
    "section": "",
    "text": "Under Construction\n\n\n\nThis tutorial is still under construction. Check back another time!"
  },
  {
    "objectID": "tutorials/psychrlogy/02_essentials/06_filter.html",
    "href": "tutorials/psychrlogy/02_essentials/06_filter.html",
    "title": "06: Filter and Select",
    "section": "",
    "text": "Under Construction\n\n\n\nThis tutorial is still under construction. Check back another time!"
  },
  {
    "objectID": "tutorials/psychrlogy/02_essentials/07_changes.html",
    "href": "tutorials/psychrlogy/02_essentials/07_changes.html",
    "title": "07: Mutate and Summarise",
    "section": "",
    "text": "Under Construction\n\n\n\nThis tutorial is still under construction. Check back another time!"
  },
  {
    "objectID": "tutorials/psychrlogy/02_essentials/08_analysis.html",
    "href": "tutorials/psychrlogy/02_essentials/08_analysis.html",
    "title": "08: Analysis",
    "section": "",
    "text": "Under Construction\n\n\n\nThis tutorial is still under construction. Check back another time!"
  },
  {
    "objectID": "tutorials/psychrlogy/03_improvRs/09_qnaires.html",
    "href": "tutorials/psychrlogy/03_improvRs/09_qnaires.html",
    "title": "09: Questionnaires",
    "section": "",
    "text": "Under Construction\n\n\n\nThis tutorial is still under construction. Check back another time!"
  },
  {
    "objectID": "tutorials/psychrlogy/03_improvRs/10_reshape.html",
    "href": "tutorials/psychrlogy/03_improvRs/10_reshape.html",
    "title": "10: Reshaping and Merging",
    "section": "",
    "text": "Under Construction\n\n\n\nThis tutorial is still under construction. Check back another time!"
  },
  {
    "objectID": "tutorials/psychrlogy/03_improvRs/11_fx.html",
    "href": "tutorials/psychrlogy/03_improvRs/11_fx.html",
    "title": "11: Functions",
    "section": "",
    "text": "Under Construction\n\n\n\nThis tutorial is still under construction. Check back another time!"
  }
]