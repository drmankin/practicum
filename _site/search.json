[
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html",
    "title": "Working with Qualtrics Data",
    "section": "",
    "text": "This tutorial will focus on efficient, transparent, and user-friendly techniques for working with data specifically gathered using the Qualtrics survey platform. We will cover how to import and work with labelled data from Qualtrics and how to easily produce a data dictionary straight from the dataset itself.\n\n\nThis tutorial was co-written with Dr Dan Evans, drawing on her existing resources for Qualtrics and her extensive experience support dissertation students.\nThe material in this tutorial was originally co-conceived with two brilliant PhD researchers, Hanna Eldarwish and Josh Francis, who contributed invaluable input throughout the process of developing the tutorial. Hanna Eldarwish also provided the basis for the dataset, collected during her undergraduate dissertation at Sussex under the supervision of Dr Vlad Costin.\n\n\n\nThe first section of the tutorial gives advice for setting up a Qualtrics questionnaire, and will help you understand how the questionnaire you build will correspond to the dataset you get at the end.\nIf you are in a live workshop or already have data to work with, jump down to Setup to get started with the data portion."
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#overview",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#overview",
    "title": "Working with Qualtrics Data",
    "section": "",
    "text": "This tutorial will focus on efficient, transparent, and user-friendly techniques for working with data specifically gathered using the Qualtrics survey platform. We will cover how to import and work with labelled data from Qualtrics and how to easily produce a data dictionary straight from the dataset itself.\n\n\nThis tutorial was co-written with Dr Dan Evans, drawing on her existing resources for Qualtrics and her extensive experience support dissertation students.\nThe material in this tutorial was originally co-conceived with two brilliant PhD researchers, Hanna Eldarwish and Josh Francis, who contributed invaluable input throughout the process of developing the tutorial. Hanna Eldarwish also provided the basis for the dataset, collected during her undergraduate dissertation at Sussex under the supervision of Dr Vlad Costin.\n\n\n\nThe first section of the tutorial gives advice for setting up a Qualtrics questionnaire, and will help you understand how the questionnaire you build will correspond to the dataset you get at the end.\nIf you are in a live workshop or already have data to work with, jump down to Setup to get started with the data portion."
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#qualtrics",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#qualtrics",
    "title": "Working with Qualtrics Data",
    "section": "Qualtrics",
    "text": "Qualtrics\nQualtrics is a survey-building tool very commonly used for questionnaire-type studies, as well as some experimental work. The University of Sussex has an institutional licence for Qualtrics, so all staff and students can log in with their Sussex details and easily construct and collaborate on surveys.\nFor help using Qualtrics itself, the Qualtrics support pages are generally excellent. This tutorial will only briefly touch on the options within Qualtrics itself.\nOnce the study is complete and responses have been collected, you will need to export your data from Qualtrics so that you can analyse it. Qualtrics offers a variety of export data types, including our familiar CSV type. However, we’re going to instead explore a new option: SAV data.\n\nSAV Data\nThe .sav file type is associated with SPSS, a widely used statistical analysis programme. So, why are we using SPSS files when working in R?\nImporting via .sav has two key advantages. First, it results in a much cleaner import format. If you try importing the same data via .csv file, you’ll find that you need to do some very fiddly and pointless cleanup first. For instance, the .csv version of the same dataset will introduce some empty rows that have to be deleted with dplyr::slice() or similar. The .sav version of the dataset doesn’t have any comparable formatting issues.\nMost importantly, however, importing .sav file types into R with particular packages like {haven} gets us a dataset with a special type of data: namely, labelled data. The labels allow us to preserve important information about the questions asked and response options in Qualtrics, and to (mostly) painlessly create codebooks for datasets. We will explore these features in depth in this tutorial.\n\n\nSetting Up Qualtrics\n\n\n\n\n\n\nImportant\n\n\n\nThe following section is most useful when you are creating your Qualtrics questionnaire. If you are just starting your study, you’re recommended to read this section in full.\nIf you already have a Qualtrics questionnaire, be very careful about editing it after data collection has begun. Minimally, if you do decide you want to make changes, export copies of both your dataset and your questionnaire before you make any edits.\nIf you have a dataset in Qualtrics, jump down to exporting data.\nIf you already have data in .sav format to work with, jump down to the next section.\n\n\nIn this section we’ll have a quick look at how to set up Qualtrics to work as smoothly as possible with R. This has also previously been covered in a QQM Skills Lab.\n\nUsing Blocks\nBlocks are the way that Qualtrics organises pieces of the survey. Essentially, everything in the same block becomes a unit. You can have multiple questions per block, or just one. Blocks are vital for creating a study that appears as you want, but they won’t have any substantial impact on the format of the data.\nExplaining blocks and how they can be arranged is a bit outside the scope of this tutorial, so see the Block Options page in the Qualtrics guide for more details.\n\n\nUsing Questions\nThe core of Qualtrics are questions, which you can create within blocks. By default, a new question is a multiple-choice question (MCQ), but you can customise this in depth in the “Edit question” sidebar to the left of the survey. To edit a question, you have to click on each question, which will outline the question in a blue box; you can then change the settings for that question in the sidebar.\n\n\n\n\n\n\nTip\n\n\n\nFor extensive help on creating and work with questions, see the Qualtrics Guide.\n\n\n\nQuestions in R\nLet’s have a look at the default question, which appears like this:\n\nAs you can see here, the way that you set up your questions translates directly into the way your dataset will appear.\n\nNames: All questions are automatically given a name, by default Q[number], e.g. Q1, Q2, etc. This question name will appear as the variable name in your exported dataset. These names are not visible to your participants.\nText: Question text is the actual question that your participants see. This question text will appear as the variable label in your exported dataset.\nChoices: For questions with a specific set of choices, like multiple-choice questions and rating scales, the choices you list here are the response options that your participants see. These choices will appear as the value labels in your exported dataset.\n\nYou may notice that there’s no evidence of the underlying numerical values for each choice. Although Qualtrics doesn’t make this immediately obvious, they are always worth checking, because sometimes they’re…creative. This doesn’t matter so much for questions that are going to become factors - whether the underlying number is 1 or 14 or 73 doesn’t matter because they’re just a marker for a unique category. However, we’ll see in a moment an example where it does matter, namely rating scales.\nTo check the values, click on the question, scroll down to the bottom of the Edit Question sidebar, and click on “x -&gt; Recode values”. This opens a new pop-up window where you can edit a few options:\n\nTick Recode Values to change the numeric values for each choice. These values are the underlying values that will appear as numbers in the dataset in R.\nTick Variable Naming to give different value labels to the choices than the ones the participants see. (Personally I’d be very wary of doing this, as it would be easy to lose track of what participants actually saw/responded to!)\n\n\nAs you can see from this simple “What’s your favourite pie?” question, these underlying numeric values can go wonky quickly. I have four options, “apple”, “cherry”, “pecan”, and “pumpkin”, which are numbered 1, 6, 2, and 3 respectively! What’s happened is that I created “apple”, “pecan”, and “pumpkin”, and then a couple other options; then I changed my mind, removed the other options (which would have been 4 and 5) and added “cherry” after “apple”. Values are assigned based on the order they are added, which is why the values came out weird and out of numerical order. If I wanted these to go in order (which isn’t a bad idea, since you want your data to be predictable), I can tick “Recode Values” and then manually enter the numeric values I want for each choice.\n\n\nMatrix Questions\nMatrix questions are very commonly used as an efficient way to present multiple questions or items with the same response scale - for example, items on a scale or subscale with a consistent Likert response scale.\nTo create one, create a “Matrix table” type question. The typical setup is for the items/questions to be presented down the left-hand side as “statements”, and the rating scale to be presented along the top as “scale points”.\nThe “Scale points” section of the Edit Question sidebar lets you control how these scale points appear. You can add or remove the number of points, and for many scales in Psychology, you can use suggested rating scales by switching the toggle on, which automatically insert labels for each scale point for you.\nMatrix tables are especially prone to issues with the underlying numeric values, especially if you use these automatic scale points. You’ll end up with really weird ranges, like 61-65, instead of 1-5, which will do a number on the interpretation of any descriptives. Even better, the numeric values change themselves every time you make changes to them! So, I’d strongly recommend you update the numeric values using “Recode values” as the last step to make sure you don’t have any surprises when you get round to looking at the data.\n\n\n\n\nExporting Data\nIf you’d like to work with your own study data, you will need to export your data in SAV format from Qualtrics first. To do this, open your Qualtrics survey and select the “Data & Analysis” tab along the top, just under the name of your survey.\nIn the Data Table view, look to the right-hand side of the screen. Click on the drop-down menu labelled “Export & Import”, then select the first option, “Export Data…”\n\nIn the “Download a data table” menu, choose “SPSS” from the choices along the top. Make sure “Download all fields” is ticked, then click “Download”.\n\nThe dataset will download automatically to your computer’s Downloads folder. From there, you should rename it to something sensible and move it into a data folder within your project folder. From there, you can read it in using the here::here() %&gt;% haven::read_sav() combo that we will seee in the Data section in just a moment.\n\n\n\n\n\n\nSensible Naming Conventions and Folder Structure\n\n\n\n\n\nSensible file and folder names will make your life so much easier for working in R (and generally).\nFor folder structure, make sure you do the following:\n\nAlways always ALWAYS use an R Project for working in R.\nHave a consistent set of folders for each project: for example, images, data, and docs.\nUse sub-folders where necessary, but consider using sensible naming conventions instead.\n\nFor naming conventions, your file name should make it obvious what information it contains and when it was created, especially for datasets like this. I recommend longer and more explicit file names over brevity.\nSo, for a download like this, I’d name it something like qtrics_diss_2024_03_20.sav. The qtrics tells me it’s a Qualtrics export, the diss tells me it’s a dissertation project, and the last bit is the full date in easily machine-readable format. Imagine if I continue to recruit participants and download a new dataset later, say a month from now, and name it qtrics_diss_2024_04_20.sav. I could easily distinguish which dataset was which by the date, but also see that they are different versions of the same thing by their shared prefix.\nThis is a much more reliable system than calling them, say, Qualtrics output.sav and Dissertation FINAL REAL.sav. This kind of naming “convention” contains no information about which is which or when they were exported, or even that they’re two versions of the same study dataset! Future You trying to figure out which dataset to use weeks or months later will feel the difference."
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#setup",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#setup",
    "title": "Working with Qualtrics Data",
    "section": "Setup",
    "text": "Setup\nThe rest of this tutorial walks you through the basics of importing, inspecting, cleaning, and converting your Qualtrics data, including automatically generating a data dictionary for reference. Data is provided to practice with in workshops, but you are welcome to follow along with your own data if you prefer.\n\nPackages\nWe will need the following packages:\n\n{tidyverse} for data wrangling.\n{haven} for importing data. This package is installed with {tidyverse} but not loaded with the core packages so needs to be loaded separately.\n{labelled} for working with labelled data.\n{sjPlot} for a data dictionary convenience function\n\n\n\n\n\n\n\nExercise\n\n\n\nLoad the packages.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(labelled)\nlibrary(sjPlot)\n\n\n\n\n\n\n\n\nData\nToday’s example dataset focuses on various aspects of meaning in life (MiL), and has been randomly generated based on a real dataset kindly contributed by Hanna Eldarwish and Vlad Costin. All variables have been randomly generated, but they are based on the patterns in the original dataset. The original, bigger dataset will be made available alongside article publication in the future, so keep an eye out for it!\n\n\n\n\n\n\nNew File Type\n\n\n\nYou might notice that instead of the familiar readr::read_csv(), today we have haven::read_sav(). We need a different function since we are using a different type of data. See the section above on .sav data for more details.\n\n\n\n\n\n\n\n\nExercise\n\n\n\nRead in the mil_data.sav object from folder, or alternatively from Github via URL, as you prefer.\nOn the Cloud, you can read in this dataset from the data folder using here::here().\nElsewhere, you can download the dataset, or copy the dataset URL, from the Data and Workbooks page.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOn the Cloud:\n\nmil_data &lt;- here::here(\"data/mil_data.sav\") %&gt;% haven::read_sav()\n\nFrom a folder:\n\nmil_data &lt;- here::here(\"data/mil_data_wkshp.sav\") %&gt;% haven::read_sav()\n\nFrom URL:\n\nmil_data &lt;- haven::read_sav(\"https://raw.githubusercontent.com/drmankin/practicum/master/data/mil_data_wkshp.sav\")\n\n\n\n\n\n\n\n\nCodebook\nThis codebook is intentionally sparse, because we’ll be generating our own from the dataset in just a moment. This table covers only the demographic and questionnaire measures to help you understand the variables.\n\n\n\n\n\n\nCodebook\n\n\n\n\n\n\n\n\n\n\n\nVariable\nItem/Scale: Subscale\n\n\n\n\nQ1\nHow well can you speak English?\n\n\nQ2\nHow old are you?\n\n\nQ3\nWhat is your gender identity?\n\n\nQ4\nWhat is your annual income?\n\n\nQ5\nWhat is your occupation?\n\n\nQ6_1\nMeaning in Life: Global Meaning (item 1)\n\n\nQ6_2\nMeaning in Life: Global Meaning (item 2)\n\n\nQ6_3\nMeaning in Life: Global Meaning (item 3)\n\n\nQ6_4\nMeaning in Life: Global Meaning (item 4)\n\n\nQ7_1\nMeaning in Life: Mattering (item 1)\n\n\nQ7_2\nMeaning in Life: Mattering (item 2)\n\n\nQ7_3\nMeaning in Life: Mattering (item 3)\n\n\nQ7_4\nMeaning in Life: Mattering (item 4)\n\n\nQ8_1\nMeaning in Life: Coherence (item 1)\n\n\nQ8_2\nMeaning in Life: Coherence (item 2)\n\n\nQ8_3\nMeaning in Life: Coherence (item 3)\n\n\nQ8_4\nMeaning in Life: Coherence (item 4)\n\n\nQ9_1\nMeaning in Life: Purpose (item 1)\n\n\nQ9_2\nMeaning in Life: Purpose (item 2)\n\n\nQ9_3\nMeaning in Life: Purpose (item 3)\n\n\nQ9_4\nMeaning in Life: Purpose (item 4)\n\n\nQ10_1\nSymbolic Immortality (item 1)\n\n\nQ10_2\nSymbolic Immortality (item 2)\n\n\nQ11_1\nBelonging (item 1)\n\n\nQ11_2\nBelonging (item 2)\n\n\nQ11_3\nBelonging (item 3)\n\n\nQ11_4\nBelonging (item 4)\n\n\nQ11_5\nBelonging (item 5)\n\n\nQ11_6\nBelonging (item 6)\n\n\nQ11_7\nBelonging (item 7)\n\n\nQ11_8\nBelonging (item 8)\n\n\nQ11_9\nBelonging (item 9)\n\n\nQ11_10\nBelonging (item 10)\n\n\nQ11_11\nBelonging (item 11)\n\n\nQ11_12\nBelonging (item 12)\n\n\n\n\n\n\n\n\n\n\nFor easy navigation, jump to: Renaming, Exercises: Names"
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#variable-names",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#variable-names",
    "title": "Working with Qualtrics Data",
    "section": "Variable Names",
    "text": "Variable Names\nQualtrics datasets are often large and unwieldy. However, they also often have a consistent structure, which we can take advantage of to work with them consistently.\n\nDefault Variable Names\nIn your dataset, you will by default have some variables that are automatically created by Qualtrics, with (somewhat) sensible names, like DistributionChannel and StartDate. You will also have all the questions that you created, and what they are called depends on what you (or, rather, the author of the questionnaire) called them.\nIf you changed the name of the questions, they will have the name that you gave them. If not, they will have a default name from Qualtrics, usually the capital letter “Q” followed by a number, like this: Q15, Q34, etc.\nIf you have matrix questions, the variable names will have a further number indicating which item in the matrix they correspond to. If, for example, your matrix question was Q23, then the responses to the first item in that matrix will be stored in Q23_1, the second in Q23_2, and so on.\nThese default variable names should be changed as a first step, before you carry on with your data processing. This is because they are easy to mix up or mistype, and difficult to remember (was it Q23 or Q32 that contained the question I wanted…?), which will lead to both unnecessary errors and extra time spent fixing problems or cross-checking which question is which.\nTo do this, we’ll get round to the dplyr::rename() function by way of a detour revising dplyr::select().\n\n\nSelecting\nYou have already encountered the function dplyr::select() as a function for keeping or dropping columns in a dataset. As a reminder, there’s some easy notation to use for variable names to quickly select single variables or ranges, or to drop variables.\n\n1dataset_name %&gt;%\n2  dplyr::select(\n3    variable_to_include,\n4    -variable_to_exclude,\n5    keep_this_one:through_this_one,\n6    new_name = variable_to_rename,\n7    variable_number\n  )\n\n\n1\n\nTake the dataset dataset_name, and then\n\n2\n\nSelect the following variables:\n\n3\n\nThe name of a variable to be included in the output. Multiple variables can be selected separated by commas.\n\n4\n\nThe name of a variable to be excluded from the output. Use either an exclamation mark (!) or a minus sign (-) in front of each variable to exclude. Multiple variables can be dropped, separated by commas with a ! (or -) before each.\n\n5\n\nA range of variables to include in the output. All the variables between and including the two named will be selected (or dropped, with !(drop_this_one:through_this_one)).\n\n6\n\nInclude variable_to_rename in the output, but call it new_name.\n\n7\n\nInclude a variable in the output by where it appears in the dataset, numbered left to right. For example, “2” will select the second column in the original dataset.\n\n\n\n\nColumns will appear in the output in the order they are selected in select(), so this function can also be used to reorder columns.\n\nSelection Helpers\nHowever, the real power in this and other {tidyverse} functions is in a system of helper functions and notations collectively called “selection helpers”, or &lt;tidyselect&gt;. The overall goal of “&lt;tidyselect&gt; semantics” (as you will see it referred to in help documentation) is to make selecting variables easy, efficient, and clear.\nThese helper functions can be combined with the selection methods above in any combination. Some very convenient options include:\n\neverything() for all columns\nlast_col() for the last column in the dataset\nstarts_with(), ends_with(), and contains() for selecting columns by shared name elements, which will be our key focus today.\nwhere() for selecting with a function, not described here (see ?where() for more)\n\nFor example, we can select specific groups of variables using the shared portions of their names, such as:\n\n“Date” for the three default Qualtrics variables containing date information\n“Q8” for the four Coherence items\n\n\nmil_data %&gt;% \n  dplyr::select(\n    contains(\"Date\"), starts_with(\"Q8\")\n  )\n\n\n\n  \n\n\n\n\n\n\nRenaming\nNow that we know how to easily select groups of variables, we need sensible names in order to make best use of those selection helpers. There are three main options for renaming variables, depending on access to the original Qualtrics questionnaire, and proficiency in R.\n\n\n\n\n\n\nImportant\n\n\n\nYou are strongly advised not to manually change the names in your dataset, e.g. in a .csv file/Excel. Not only will you lose the labels, but this is very prone to error with no record of the changes made.\n\n\n\nOption 1: Rename in Qualtrics\nThis option requires that you have have access to, and are willing to edit, the original Qualtrics questionnaire. Rather than being a coding option, this entails going back to the Qualtrics questionnaire and changing the question labels before you export the dataset.\nFor more on this, see Setting Up Qualtrics.\n\n\nOption 2: rename()\nThe friendly dplyr::rename() function does exactly what it says on the tin. In general:\n\n1dataset_name %&gt;%\n2  dplyr::rename(\n3    new_name = old_name\n  )\n\n\n1\n\nTake the dataset dataset_name, and then\n\n2\n\nRename the following variables:\n\n3\n\nThe new name (new_name) you would like to give to an existing variable (old_name).\n\n\n\n\nYou can list as many of these new_name = old_name pairs as you like. For example, let’s rename the Global Meaning items so they have sensible prefixes (refer to the Codebook for which variables these are!). We should keep the item numbers as they are, so we know which one is which.\n\nmil_data %&gt;% \n  dplyr::rename(\n    meaning_1 = Q6_1,\n    meaning_2 = Q6_2,\n    meaning_3 = Q6_3,\n    meaning_4 = Q6_4,\n  )\n\n\n\n  \n\n\n\nThis option allows you to easily keep track of the renaming you’ve done in your code, but it is very tedious and intensive, especially if you have many variables that need renaming.\n\n\nOption 3: rename_with()\nThis option requires considerable proficiency and experience with R. It is by far the quickest and most efficient of these options, but you must be able to write anonymous functions, use regular expressions and selection helpers, and have good working knowledge of how to debug errors and check output. If any of those things are unfamiliar, use one of the two previous options instead.\n\n\n\n\n\n\nHaRd Mode: Using rename_with()\n\n\n\n\n\nThe versatile dplyr::rename_with() function allows quick, efficient, and accurate renaming of large groups of variables at once. The general form is:\n\ndataset_name %&gt;%\n  dplyr::rename_with(\n     .fn = function_to_apply,\n     .cols = variables_to_rename\n  )\n\n\n\n\n\n\nThe “function to apply” here could be simply the name of an existing function, for example tolower (convert to lowercase). You can also write a “purrr-style lambda” function, which will allow you to write your own custom function to change the variable names however you please.\nAs an example, let’s convert the Q11 variables in the dataset at once. We know from the codebook that these are all items on the Belonging subscale, so we want to replace the string “Q11” in the variable names to “belonging”.\n\n1mil_data %&gt;%\n  dplyr::rename_with(\n2    .fn = ~ gsub(\"Q11\", \"belonging\", .x),\n3    .cols = dplyr::starts_with(\"Q11\")\n  )\n\n\n1\n\nTake the mil_data dataset and then rename variables as follows\n\n2\n\nReplace every instance of the string “Q11” with the string “belonging”\n\n3\n\nDo this for every column that currently starts with the string “Q11”\n\n\n\n\n\n\n  \n\n\n\nIn this command, our “purrr-style lambda” is the anonymous function ~ gsub(\"Q23\", \"belonging\", .x). The ~ (apparently pronounced “twiddle”) at the beginning is a shortcut for the longer function(x) ... notation for creating functions. The .x is a placeholder for each of the variables that the function will be applied to. These are both used in a customised version of the base-R gsub() function, which generally substitutes every match with its first argument with the replacement in its second argument for the vector of possibilities in its third argument; see ?gsub() for details.\nAs you can see from the output, this only replaces the relevant portion of the column name, leaving the numbered item suffixes unchanged. If you are proficient in working with regular expressions and string manipulation, you can use this technique to programmatically rename variables very easily."
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#exercises-names",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#exercises-names",
    "title": "Working with Qualtrics Data",
    "section": "Exercises: Names",
    "text": "Exercises: Names\nBefore we go on, it’s time to get the variables in this dataset sorted out. You must do this, or the solutions further on in the document won’t work!\n\n\n\n\n\n\nExercise\n\n\n\nClean up your dataset by doing the following. You can do the steps in whatever order works for you.\n\nKeep all the demographic questions, items measuring Global Meaning, and Mattering, and all the Belonging items.\nRename any default-named Qualtrics variables (starting with “Q”) to a sensible name.\n\nRefer to the Codebook to figure out which variables are which.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou can accomplish this task in either order:\n\nFirst, select the variables you want, then rename them.\nSecond, rename the variables, then select them.\n\nThis solution will give answers in the order of the sections above, so first select and then rename. However, consider that if you need to go back and change your selection later, this will be easier if the variables are named something sensible, so it’s worth considering renaming first, before you do anything else, for your own data.\nBoth tasks could be done in one pipeline, but to break it down, in this first chunk we have selected the range of demographic variables, and the Global Meaning and Mattering scale items by using the the colon between Q1 and Q7_4, and have selected the Belonging scale items which all start with 'Q11'.\n\nmil_data &lt;- mil_data %&gt;% \n  dplyr::select(\n    Q1:Q7_4,\n    starts_with('Q11')\n    ) \n\nFor the second task, we need to decide on “sensible” names. You can choose anything that makes sense to you, but we will use global_meaning for Q6, mattering for Q7, and belonging for Q11.\nIn our second pipeline, we’re using rename() to replace the names of each variable individually. If you did this yourself before looking at the solution, you will likely have found this to be a laborious, tedious, and error-prone process, so for your own data, make sure you allow time to both do and check this code.\n\nmil_data &lt;- mil_data %&gt;% \n  dplyr::rename(\n    english_fluency = Q1, \n    age = Q2,\n    gender = Q3,\n    income = Q4,\n    occupation = Q5,\n    global_meaning_1 = Q6_1,\n    global_meaning_2 = Q6_2,\n    global_meaning_3 = Q6_3,\n    global_meaning_4 = Q6_4,\n    mattering_1 = Q7_1,\n    mattering_2 = Q7_2,\n    mattering_3 = Q7_3,\n    mattering_4 = Q7_4,\n    belonging_1 = Q11_1,\n    belonging_2 = Q11_2,\n    belonging_3 = Q11_3,\n    belonging_4 = Q11_4,\n    belonging_5 = Q11_5,\n    belonging_6 = Q11_6,\n    belonging_7 = Q11_7,\n    belonging_8 = Q11_8,\n    belonging_9 = Q11_9,\n    belonging_10 = Q11_10,\n    belonging_11 = Q11_11,\n    belonging_12 = Q11_12\n  )\n\nAlternatively, if you ventured into Option 3 for renaming above, you could instead use rename_with() to rename all the items starting with 'Q6' to have the prefix of 'global_meaning', all the items starting with 'Q7' to have the prefix of 'mattering', and all the items starting with 'Q11' to have the prefix of 'belonging'.\n\nmil_data &lt;- mil_data %&gt;% \n  dplyr::rename(\n    english_fluency = Q1, \n    age = Q2,\n    gender = Q3,\n    income = Q4,\n    occupation = Q5 \n  ) %&gt;% \n  dplyr::rename_with( \n    .fn = ~ gsub(\"Q6\", \"global_meaning\", .x),  \n    .cols = dplyr::starts_with(\"Q6\")\n  ) %&gt;% \n  dplyr::rename_with( \n    .fn = ~ gsub(\"Q7\", \"mattering\", .x),  \n    .cols = dplyr::starts_with(\"Q7\")\n  ) %&gt;% \n  dplyr::rename_with( \n    .fn = ~ gsub(\"Q11\", \"belonging\", .x),  \n    .cols = dplyr::starts_with(\"Q11\") \n  )"
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#labelled-data",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#labelled-data",
    "title": "Working with Qualtrics Data",
    "section": "Labelled Data",
    "text": "Labelled Data\nWith the minimal necessary cleaning out of the way, we can now move on to exploring labelled data.\n\n\n\n\n\n\nThe Plan\n\n\n\nOur workflow for this dataset will be slightly different than you may have encountered before.\nWe’ll start by checking the labels and producing a codebook, or “data dictionary”, drawing on the label metadata in the SAV file. For the purpose of practice, we’ll also have a look at how to work with those labels, and optionally manage different types of missing values.\nAs useful as labels are, they will get in the way when we want to work with our dataset further. So, we’ll next convert the variables in the dataset into either factors, for categorical data, or numeric, for continuous data 1. From that point forward, we can work with the dataset using the techniques and functions we’ve covered throughout first and second year.\n\n\n\nWorking with Labels\nThe SAV data we’re using has a special property: labels. Labelled data has a number of features, which we will explore in depth shortly:\n\nVariable labels. The label associated with a whole variable will contain the text of the item that the participants responded to. This is analogous to the “Label” column of the Variable View in SPSS.\nValue labels. The label associated with individual values within a variable will contain the text associated with individual choices, for instance the points on a Likert scale or the options on a multiple-choice question. This is analogous to the “Values” column of the Variable View in SPSS.\nMissing values. Within value labels, you can designate particular values as indicative of missing responses, refusal to respond, etc. This is analogous to the “Missing” column of the Variable View in SPSS.\n\nWe’re first going to look at how you can work with each of these elements. The reason to do this is that once our dataset has been thoroughly checked, we’re going to generate a final data dictionary, then convert any categorical variables into factors, the levels of which will correspond to the labels for that variable. We’ll also convert any numeric variables into numeric data type, which will discard the labels; that will make it possible to do analyses with them, but that’s why we have to create the data dictionary first.\nMost of the following examples are drawn from the “Introduction to labelled” vignette from the {labelled} package. If you want to do something with labelled data that isn’t covered here, that’s a good place to start!\n\n\n\n\n\n\nImportant\n\n\n\nThese features will work optimally only if you have set up your Qualtrics questionnaire appropriately. Make sure to refer to the Setting Up Qualtrics section to get the most out of your labelled data and save yourself data cleaning and wrangling headaches later.\n\n\n\n\nVariable Labels\nVariable labels contain information about the whole variable, and for Qualtrics data, will by default contain either an automatically generated Qualtrics value (like “Start Date”), or the question text that that variable contains the responses to.\n\nGetting Labels\nTo begin, let’s just get out a single variable label to work with using labelled::var_label().\nTo specify the variable we want, we will need to subset it from the dataset, using either $ or dplyr::pull().\n\nlabelled::var_label(mil_data$gender)\n\n[1] \"What is your gender identity?  This question is optional. - Selected Choice\"\n\n\n\n\nCreating/Updating Labels\nIf you’d like to edit labels, you can do it “manually” - that is, just writing a whole new label from scratch.\nThe structure of the following code might look a little unfamiliar. For the most part, we’ve seen code that contains longer and more complex instructions on the right-hand side of the &lt;-, and a single object being created or updated on the left-hand side. In the structure below, the left-hand side contains longer and more complex code that identifies the value(s) to be updated or created, and the right-hand side contains the value(s) to create or update. It’s the same logic, just with a different structure.\n\nlabelled::var_label(mil_data$StartDate) &lt;- \"Date and time questionnaire was started\"\n\nlabelled::var_label(mil_data$StartDate)\n\n\n\n[1] \"Date and time questionnaire was started\"\n\n\n\n\n\n\n\n\nHaRd Mode: Using Regular Expressions\n\n\n\n\n\nRegular expressions are the magic of working with code. They are also fiddly, confusing, and difficult. If you’re not keen on spending a lot of time learning what is in essence a new mini-language, skip this section!\nEditing labels is a good opportunity to start working with regular expressions. For example, if we want to keep only the first bit of the label for gender, then we can keep everything only up to and including the question mark, and re-assign that to the variable label. This style is a bit more dynamic and resilient to changes or updates.\n\nlabelled::var_label(mil_data$gender) &lt;- labelled::var_label(mil_data$gender) %&gt;%\n  gsub(\"(.*\\\\?).*\", \"\\\\1\", x = .)\n\nlabelled::var_label(mil_data$gender)\n\n\n\n[1] \"What is your gender identity?\"\n\n\nLet’s pick apart this gsub() command a bit at a time. First, gsub() has three arguments:\n\npattern, here \"(.*\\\\?).*\", which is the regex statement representing the string to match.\nreplacement, here \"\\\\1\", which is the string that should replace the match in pattern.\nx, the string to look in.\n\nThe pattern has essentially two parts: the bit in the rounded brackets, and the bit outside. The rounded brackets designate a “capturing group” - a portion of the string that should be grouped together as a unit. The benefit of this grouping is in the second argument of gsub(); \\\\1 isn’t the number 1, but rather is a pronoun referring to the first capturing group. In other words, as a whole, this gsub() command captures a subset of the incoming string, and then replaces the entire string with that captured string, essentially dropping everything outside the capturing group.\nTo understand the regex statement \"(.*\\\\?).*\", we need to look at the incoming text, x. In this case, x is being piped in from above and looks like this:\n\nlabelled::var_label(mil_data$gender)\n\n[1] \"What is your gender identity?  This question is optional. - Selected Choice\"\n\n\n.* is a common regex shorthand that means “match any character, as many times as possible.” It’s essentially an “any number of anything” wildcard. This wildcard appears both inside and outside the brackets. So, how does gsub() know which bit should belong in the capturing group?\nThe answer is \\\\?. This is a “literal” question mark. Some symbols, like . and ?, are regex operators, but we might want to also match the “literal” symbols full-stop “.” and question mark “?” in a string. In this case we need an “escape” character “\\\", that escapes regex and turns the symbol into a literal one. So, the capturing group ends with a literal question mark - in the target string, that’s the question mark after”identity”, which is the only one in the string.\nAs an aside, if you’re wondering why there are two escape characters instead of one - i.e., why is it \\\\? and not \\?, well, you and me both. There’s an explanation in vignette(\"regular-expressions\") that never completely makes sense to me. Also, this seems to be an R thing - regex outside of R seems to use only a single escape character, so a literal question mark would be \\?. If you are ever trying to adapt regex from e.g. StackOverflow or regex101 and it isn’t working, check whether the escape characters are right!\nAnyway. We can now read \"(.*\\\\?)\" as “capture all characters up to and including a literal question mark” - which matches the substring “What is your gender identity?” in x. However, we don’t just want to replace that portion of the string - instead, we want to replace the whole string with that bit of it. So, the second .* outside the brackets matches the rest of the string. If we didn’t include this last bit, the capturing group would just be replaced with itself, which would result in the same string as we started with, as below:\n\nlabelled::var_label(mil_data$gender) %&gt;%\n  gsub(\"(.*\\\\?)\", \"\\\\1\", x = .)\n\n[1] \"What is your gender identity?  This question is optional. - Selected Choice\"\n\n\nSo, altogether, we can read this gsub() command as: “Capture everything up to an including the question mark, and replace the entire string with that capturing group.”\nNow. Why, you might wonder, is all this faff better?\nWell, it might not be. You might find it more frustrating or effortful to generate the right regex pattern than to replace the label “manually”, and in that case, there’s nothing wrong with just writing out the label you want.\nOn the other hand, the regex command will always drop everything after the question mark, no matter what that text is. If there is no match, it won’t replace anything. So, unlike the “manual” option, there’s much less danger of accidentally mixing up labels or overwriting the wrong thing; and this regex statement can be generalised to any label that contains a question mark, rather than having to type out each label one by one.\n\n\n\n\n\nSearching Labels\nA very nifty feature of variable labels and {labelled} is the ability to search through them with labelled::look_for(). With the whole dataset, look_for() returns a whole codebook (see Data Dictionaries below for more on this), but given a second argument containing a search term, you get back only the variables whose label contains that term.\nFor example, we can use labelled::look_for() to get only the items in this questionnaire that mentioned family. (I’ve piped into tibble::as_tibble() to make the output easier to read.)\n\nlabelled::look_for(mil_data, \"family\") %&gt;%\n  tibble::as_tibble()\n\n\n\n  \n\n\n\n\n\n\nValue Labels\nValue labels contain individual labels associated with unique values within a variable. It’s not necessary to have a label for every value, but for our purposes, it’s important that all values that represent categories have a label.\n\nGetting Labels\nThere are two functions to assist with this. labelled::val_labels() (with an “s”) returns all of the labels, while labelled::val_label() (without an “s”) will return the label for a single specified value.\n\nlabelled::val_labels(mil_data$english_fluency)\n\n Very well       Well   Not well Not at all \n         1          2          3          4 \n\n\n\nlabelled::val_label(mil_data$english_fluency, 3)\n\n[1] \"Not well\"\n\n\n\n\nCreating/Updating Labels\nThese two functions can also be used to update an entire variable or a single value respectively. The structure of this code is the same as we saw with variable labels previously.\nFor example, let’s get all the value labels for the gender variable, then update the last value to “Other”.\nFirst, return the existing labels:\n\nlabelled::val_labels(mil_data$gender)\n\n                      Male                     Female \n                         0                          1 \n                Non-binary Other (please state below) \n                         2                          3 \n\n\nThen, replace the label associated with the value 3:\n\nlabelled::val_label(mil_data$gender, 3) &lt;- \"Other\"\n\n\n\n\nMissing Values\nThis section is included especially for people who may have previous experience with SPSS, and are learning how to adapt their SPSS knowledge to R. Unless you make regular use of SPSS’s alternative options for managing missing values, you can skip this section.\n\n\n\n\n\n\nHaRd Mode: Missing Values\n\n\n\n\n\nLabelled data allows an extra functionality from SPSS, namely to create user-defined “missing” values. These missing values aren’t actually missing, in the sense that the participant didn’t respond at all. Rather, they might be missing in the sense that a participant selected an option like “don’t know”, “doesn’t apply”, “prefer not to say”, etc.\nLet’s look at an example. As we’ve just seen, we can get out all the value labels in variable with labelled::val_labels():\n\nlabelled::val_labels(mil_data$english_fluency)\n\n Very well       Well   Not well Not at all \n         1          2          3          4 \n\n\nThis variable asked participants to indicate their level of English fluency. Even for participants who have in fact responded to this question, we may want to code “Not well” and “Not as all” as “missing” so that they can be excluded easily. To do this, we can use the function labelled::na_values() to indicate which values should be considered as missing.\n\nlabelled::na_values(mil_data$english_fluency) &lt;- 3:4\n\nmil_data$english_fluency\n\n&lt;labelled_spss&lt;double&gt;[164]&gt;: Please select which box best describes your English fluency. - How well can you speak English?\n  [1] 2 2 2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 2 1 1 1\n [75] 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 2\n[112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[149] 1 1 1 1 1 1 1 1 1 2 1 1 1 1 3 2\nMissing values: 3, 4\n\nLabels:\n value      label\n     1  Very well\n     2       Well\n     3   Not well\n     4 Not at all\n\n\nFor the moment, these values are not actually NA in the data - they’re listed under “Missing Values” in the variable attributes. In other words, the actual responses are still retained. However, if we ask R which of the values in this variable are missing…\n\nis.na(mil_data$english_fluency)\n\n  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[121] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[157] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n\n\n…we can see one TRUE corresponding to the 3 above.\nIf we wanted to actually remove those values entirely and turn them into NAs for real, we could use labelled::user_na_to_na() for that purpose. Now, the variable has only two remaining values, and any 3s and 4s have been replaced.\n\nlabelled::user_na_to_na(mil_data$english_fluency)\n\n&lt;labelled&lt;double&gt;[164]&gt;: Please select which box best describes your English fluency. - How well can you speak English?\n  [1]  2  2  2  1  1  1  2  1  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n [26]  1  1  1  1  1  1  1  1  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n [51]  1  1  2  1  1  1  1  1  1  1  1  2  1  1  1  2  1  1  1  1  2  1  1  1  1\n [76]  1  1  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1\n[101]  1  1  2  1  1  1  1  1  1  2  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n[126]  1  1  1  2  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n[151]  1  1  1  1  1  1  1  2  1  1  1  1 NA  2\n\nLabels:\n value     label\n     1 Very well\n     2      Well\n\n\n\n\n\n\n\n\nTip\n\n\n\nSee the {labelled} vignette for more help on working with user-defined NAs, including how to deal with them when converting to other types."
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#exercises-labels",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#exercises-labels",
    "title": "Working with Qualtrics Data",
    "section": "Exercises: Labels",
    "text": "Exercises: Labels\nThe following exercises will help you get some hands-on practice with working with labels. You’re strongly recommended to try them yourself before you carry on.\n\n\n\n\n\n\nExercise\n\n\n\nIdentify the item that mentions ‘job’. Then, change the variable label of this item so that it just says ‘Occupational Status’\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## Find the variable\nlabelled::look_for(mil_data, \"job\") %&gt;%\n  tibble::as_tibble()\n\n\n\n  \n\n\n## Update the label\nlabelled::var_label(mil_data$occupation) &lt;- \"Occupational Status\"\n\n## Check the new label\nlabelled::var_label(mil_data$occupation)\n\n[1] \"Occupational Status\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nFor the income variable, change the value label ‘I prefer not to disclose information about my annual income as part of this research study.’ to ‘Prefer not to say.’\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## View current labels\nlabelled::val_labels(mil_data$income)\n\n                                                                          Less than £15,000 \n                                                                                          1 \n                                                                          £15,000 - £29,999 \n                                                                                          2 \n                                                                          £30,000 - £44,999 \n                                                                                          3 \n                                                                          £45,000 - £59,999 \n                                                                                          4 \n                                                                          £60,000 - £74,999 \n                                                                                          5 \n                                                                          £75,000 - £89,999 \n                                                                                          6 \n                                                                          More than £90,000 \n                                                                                          7 \nI prefer not to disclose information about my annual income as part of this research study. \n                                                                                          8 \n\n\n\n## Replace the correct value\nlabelled::val_label(mil_data$income, 8) &lt;- \"Prefer not to say.\"\n\n## Check this has been done correctly\nlabelled::val_labels(mil_data$income)\n\n Less than £15,000  £15,000 - £29,999  £30,000 - £44,999  £45,000 - £59,999 \n                 1                  2                  3                  4 \n £60,000 - £74,999  £75,000 - £89,999  More than £90,000 Prefer not to say. \n                 5                  6                  7                  8"
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#data-dictionaries",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#data-dictionaries",
    "title": "Working with Qualtrics Data",
    "section": "Data Dictionaries",
    "text": "Data Dictionaries\nOnce our labels have been cleaned and updated, we can finally produce a data dictionary for this dataset.\n\n\n\n\n\n\nWhy a data dictionary?\n\n\n\n\n\nThere’s two key reasons to produce a data dictionary for your dataset.\nFirst, data dictionaries (or “codebooks”) are very useful for understanding datasets, even your own. You may find yourself referring to it frequently when writing your methods and results, to remind yourself what different questions contain, what the text of the question was, etc.\nSecond, data dictionaries are hugely useful for other people. This would be a massive help to, for example, your supervisor who may need to assist you with your data analysis, or to include in your dissertation submission for your markers. If you want to share your data publicly, including a dictionary/codebook is not only a kindness to other users but also helps prevent misuse or misunderstandings.\n\n\n\nIf you primarily need a quick reference as you’re working with your dataset, the delightful sjPlot::view_df() function makes this particularly easy.\nLet’s put mil_data into the sjPlot::view_df() function and see what it does. By default, the document opens in the Viewer, but you can also save the file it creates for further sharing - see the help documentation.\n\nsjPlot::view_df(mil_data)\n\nIf you’re happy with this, this is probably all you need to carry on. If you are keen to create your data dictionary as a dataset that you could further edit - or if you’d like a version of the data dictionary that more closely emulates SPSS’s Variable View - see below.\n\n\n\n\n\n\nHaRd Mode: Editable Data Dictonary\n\n\n\n\n\nUse the generate_dictionary() function from the {labelled} packages to create a data dictionary for mil_data. To have the best look at it, I would recommend using View() to review it.\n\nmil_data %&gt;%\n  labelled::generate_dictionary() %&gt;%\n  View()\n\n\n\n\n\n  \n\n\n\nUnlike the output from sjPlot::view_df(), the output from this function is a dataset that you can work with. This means you can edit it using any of your {dplyr} skills and render it as a table in a document if you like. The sky’s the limit!"
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#converting-variables",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#converting-variables",
    "title": "Working with Qualtrics Data",
    "section": "Converting Variables",
    "text": "Converting Variables\nThe labels have served their purpose helping us navigate and clean up the dataset, and produce a lovely data dictionary for sharing. However, if we want to use the data, we’ll need to convert to other data types that we can use for statistical analysis.\nHow we convert each variable will fall into two main categories:\n\nAny variables containing categorical data, we’ll convert to factors, which will use the value labels as factor levels\nAny variables containing numbers that we want to do maths with, we’ll convert to numeric, which will strip the labels.\n\n\n\n\n\n\n\nImportant\n\n\n\nVariables that will be converted to factor should have labels for all of their levels, whereas variables that will be converted to numeric can have fewer labels, because we will stop using them after the numeric conversion.\n\n\n\nFactors\nFactor variables are R’s way of representing categorical data, which have a fixed and known set of possible values.\nFactors actually contain two pieces of information for each observation: levels and labels. Levels are the (existing or possible) values that the variable contains, whereas labels are very similar to the labels we’ve just been exploring.\nIf you feel confident understanding and working with factors in R, you can skip the box below.\n\n\n\n\n\n\nRevision of Factors\n\n\n\nLet’s start by looking at an example factor to see how it appears. This isn’t in our dataset; instead, we can create factor data using the factor() function.\n\nfactor(c(1, 2, 1, 1, 2),\n       labels = c(\"Male\", \"Female\"))\n\n[1] Male   Female Male   Male   Female\nLevels: Male Female\n\n\nThe underlying values in the factor are numbers, here 1 and 2. The labels are applied to the values in ascending order of those values, so 1 becomes “Male”, “2” becomes “Female”, etc. Here, we don’t need to specify the levels; if you don’t elaborate otherwise, R will assume that they are the same as the unique values.\nYou can also supply additional possible values, even if they haven’t been observed, using the levels argument:\n\nfactor(c(1, 2, 1, 1, 1),\n       levels = c(1, 2, 3),\n       labels = c(\"Male\", \"Female\", \"Non-binary\"))\n\n[1] Male   Female Male   Male   Male  \nLevels: Male Female Non-binary\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFactors are so common and useful in R that they have a whole {tidyverse} package to themselves! You already installed {forcats} with {tidyverse}, but you can check out the help documentation if you’d like to learn more about working with factors.\n\n\n\nConverting to Factors\nLabelled data is very easy to convert into factors, which is what R expects for many different types of analysis and plotting functions. Handy!\nFor an individual variable, we can use labelled::to_factor() to convert to factor.\nFor example, we can convert the gender variable to factor as follows, using the dplyr::mutate() function to make a change to the dataset. Remember that using the same variable name as we have done here means that the existing variable will be replaced (overwritten) in the dataset.\nIf we look at only this particular variable, we can see that its data type is now &lt;fctr&gt;, which is what we wanted.\n\nmil_data %&gt;% \n  dplyr::mutate(\n    gender = labelled::to_factor(gender)\n  ) %&gt;% \n  dplyr::select(gender)\n\n\n\n  \n\n\n\nIf you wanted a specific order of the levels, for plotting or similar, there’s also a sort_levels = argument described in the help documentation for labelled::to_factor().\nThat’s actually it! Whatever the value labels are in the variable, they will be converted into factor labels. Assuming your value labels are correct, no further editing is needed.\n\n\n\nNumeric\nFor continuous variables, we don’t need anything fancy to turn them into numeric data, because they technically already are. Instead, we just need to get rid of the labels using unclass().\nAs an example, we can use unclass() to convert belonging_1 to numeric, using the dplyr::mutate() function to make a change to the dataset again.\nIf we look at only this particular variable, we can see that its data type is now &lt;dbl&gt;, which is again what we wanted.\n\nmil_data %&gt;% \n  dplyr::mutate(\n    belonging_1 = unclass(belonging_1)\n  ) %&gt;% \n  dplyr::select(belonging_1)\n\n\n\n  \n\n\n\nFrom here, you can convert variables one by one as necessary…or, for a (much!) more efficient method, read on.\n\n\nEfficient Conversion\nDepending on the size of your dataset, converting your variables one by one to either factor or numeric might range from mild inconvenience to massive undertaking. In this optional section, we will make use of what we covered previously about selection helpers in combination with a new function, dplyr::across(), to convert multiple variables at once.\nThe general form is:\n\n1dataset_name %&gt;%\n  dplyr::mutate(\n2     dplyr::across(\n3        .cols = variables_to_change,\n4        .fn = function_to_apply\n     )\n  )\n\n\n1\n\nTake the dataset dataset_name, and then make a change to it as follows\n\n2\n\nApply to…\n\n3\n\nThe variables selected to be changed\n\n4\n\nA function to apply to each of the selected variables\n\n\n\n\nIn the first .cols argument, we use &lt;tidyselect&gt; syntax (i.e. selection helpers) to choose which variables we want to change.\nIn the second argument, the function or expression in function_to_apply is applied to each of the variables we’ve chosen.\nAs an example, we can change all of the mattering variables at once as follows:\n\nmil_data %&gt;%\n  dplyr::mutate(\n     dplyr::across(\n        .cols = starts_with(\"mattering\"),\n        .fn = unclass\n     )\n  )\n\n\n\n  \n\n\n\nHere I’ve used the dplyr::starts_with() function to choose which variables I want to change, and then each of those variables will have the unclass() function applied to them, converting them to numeric. This is exactly the same result as:\n\nmil_data %&gt;%\n  dplyr::mutate(\n    mattering_1 = unclass(mattering_1),\n    mattering_2 = unclass(mattering_2),\n    mattering_3 = unclass(mattering_3),\n    mattering_4 = unclass(mattering_4)\n  )\n\n…but with no risk of accidentally replacing variables with the wrong values due to copy/paste or typing mistakes."
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#calculating-variables",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#calculating-variables",
    "title": "Working with Qualtrics Data",
    "section": "Calculating Variables",
    "text": "Calculating Variables\nAs a final topic to get you ahead on your data analysis, this last section is a brief revision/reference of key topics you’ve already covered previously in your core methods modules. First, we’ll revise reverse-coding, to reverse the direction of responses on particular items as necessary. Once that’s done, we can create scores for each group of items that belong to the same subscale to get overall subscale scores to use in analysis.\n\n\n\n\n\n\nTip\n\n\n\nBoth reverse-coding and composite scores, including the underlying concepts and the code, have previously been covered in last year’s QQM Skills Lab.\n\n\n\nReverse Coding\nYou may or not have items in your questionnaire that are reverse-coded. There’s nothing in the data that will tell you this; you have to know what’s in your questionnaire, how the questions were designed, and which item(s) need reverse-coding. Make sure you check this carefully before you go on if working with your own data.\n\n\n\n\n\n\nWhat is reverse-coding?\n\n\n\n\n\nIn many multi-item measures, some items are reversed in the way that they capture a particular construct. For example, items on the State-Trait Inventory of Cognitive and Somatic Anxiety (STICSA, not in this example data) are worded so that a higher numerical response (closer to the “very much so” end of the scale) indicates more anxiety, such as item 4: “I think that others won’t approve of me”.\nHowever, reverse-coded items are intended to capture the same ideas, but in reverse. A reversed version a STICSA item might read, “I can concentrate easily with no intrusive thoughts.” In this case, a higher numerical response (closer to the “very much so” end of the scale) would indicate less anxiety. In order for these reversed items to be aligned with the other items on the scale, so that together they form a cohesive score, the coding of the response scale must be flipped: high becomes low, and low becomes high.\nIf the response scale is a numerical integer sequence, as this one is, then the simplest way to reverse-code the responses is to subtract every response from the maximum possible response plus one. For the STICSA, the response scale ranges from 1 to 4; the maximum possible response is 4, plus one is 5. So, to reverse-code the responses, we would need to subtract each rating on this item from 5. A high score (4) will be become a low score (5 - 4 = 1), and vice versa for a low score (5 - 1 = 4).\n\n\n\nIn order to reverse-code a variable, we will need to make use again of the dplyr::mutate() function for changing variables. For example, let’s reverse-code mattering_32.\nFirst, we need to know the maximum possible value in this variable. Using our data dictionary, we can see that values range from 1 to 7. So, to reverse-code, we should subtract each value from the max value plus one = 7 + 1 = 8.\nThen, we simply overwrite the existing variable with the new scores:\n\nmil_data %&gt;% \n  dplyr::mutate(\n    mattering_3 = 8 - mattering_3\n  )\n\nNote that it is recommended to overwrite the item, rather than create a new variable, so that you don’t accidently include the wrong or multiple versions in the next step.\n\n\nComposite Scores\nOnce all your items are cleaned and reverse-scored, you can finally create a composite score. For example, we have four mattering items, that we can combine into a “composite” score measuring general performance across all items. How this composite is calculated will depend on the questionnaire you’re using, but as many questionnaire subscale scores use mean scores3, we will demonstrate that here.\nTo do this, we need two new functions.\n\nThe first new function, dplyr::c_across(), provides an efficient way to select multiple variables to contribute to the calculation - namely, by using &lt;tidyselect&gt; selection helpers.\nThe second new function is actually a pair of functions, dplyr::rowwise() and dplyr::ungroup(). These two respectively impose and remove an internal structure to the dataset, such that each row is treated like its own group, and any operations are done within those row-wise groups.\n\nLet’s see the combination of these two in action to create a mattering composite score.\n\n\n\n\n\n\nImportant\n\n\n\nThe code below assumes a dataset structured so there is information from each participant on only and exactly one row in the dataset.\nIf your data has observations from the same participants on multiple rows, you will need to reshape your data or otherwise adapt the code to suit your data structure.\n\n\n\n1mil_data |&gt;\n2  dplyr::rowwise() |&gt;\n3  dplyr::mutate(\n    mattering_comp = mean(c_across(starts_with(\"mattering\")),\n                        na.rm = TRUE)\n  ) |&gt;\n4  dplyr::ungroup()\n\n\n1\n\nOverwrite the mil_data dataset with the following output: take the existing mil_data dataset, and then\n\n2\n\nGroup the dataset by row, so any subsequent calculations will be done for each row separately, and then\n\n3\n\nCreate the new mattering_comp variable by taking the mean of all the values in variables that start with the string “mattering” (ignoring any missing values), and then\n\n4\n\nRemove the by-row grouping that was created by rowwise() to output an ungrouped dataset.\n\n\n\n\n\n\n  \n\n\n\nIf you don’t feel comfortable using selection helpers, you can list variables instead inside c_across() using c() to combine them:\n\nmil_data |&gt;\n  dplyr::rowwise() |&gt;\n  dplyr::mutate(\n    mattering_comp = mean(c_across(c(mattering_1, mattering_2, mattering_3, mattering_4)),\n                        na.rm = TRUE)\n  ) |&gt;\n  dplyr::ungroup()\n\nHowever, you’re strongly recommended to get the hang of selection helpers, since they are both easy to read and use and extremely versatile!\n\n\n\n\n\n\nRunning Code Out of Order\n\n\n\nUsing selection helpers like this does have a potential issue: it will give you the wrong answer if you run the same code more than once, or out of the order.\nIn the first example above using starts_with(), this command calculates the mean across all of the variables in the data whose names start with the string “mattering”. This will be mattering_1, mattering_2, mattering_3, and mattering_4.\nHowever, if you run the same code a second time, the command will again calculate the mean across all of the variables in the data whose names start with the string “mattering”. This will be mattering_1, mattering_2, mattering_3, mattering_4 - AND mattering_comp, which was created previously.\nAlthough the second example above enumerating individual variable names doesn’t have this danger, it’s still better to use the selection helpers, and simply never run your code out of order."
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#exercises-conversion-and-wrangling",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#exercises-conversion-and-wrangling",
    "title": "Working with Qualtrics Data",
    "section": "Exercises: Conversion and Wrangling",
    "text": "Exercises: Conversion and Wrangling\n\n\n\n\n\n\nExercise\n\n\n\nPrepare the mil_data dataset for analysis.\n\nProduce a final data dictionary and save it.\nConvert all categorical variables to factor, and all scale rating variables to numeric.\nReverse-code global_meaning_2.\nCreate composite scores for all of the subscale variables.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nProduce a final data dictionary and save it.\n\nUsing the help documentation, we can see there is a file argument. Providing a file path/name will save the output of this file into that file. For example, the command below will save the data dictionary as an HTML file to review or share.\n\nsjPlot::view_df(mil_data, file = \"diss_dict.html\")\n\n\nConvert all categorical variables to factor, and all scale rating variables to numeric.\n\nThis can again be accomplished multiple ways. The first way involves listing each variable one by one. Below just a couple of variables are listed, but this would need to be done individually for every variable in the dataset that needs conversion.\n\nmil_data %&gt;% \n  dplyr::mutate(\n    english_fluency = labelled::to_factor(english_fluency),\n    mattering_1 = unclass(mattering_1),\n    ...\n  )\n\nInstead, you are strongly recommended to use dplyr::across() and selection helpers.\n\nmil_data &lt;- mil_data %&gt;% \n  dplyr::mutate(\n    ## Change all grouping variables to factor\n    dplyr::across(c(english_fluency, gender, income, occupation),\n                  labelled::to_factor),\n    ## Change all subscale items to numeric\n    dplyr::across(contains(c(\"mattering\", \"global_meaning\", \"belonging\")),\n                  unclass)\n  )\n\n\nReverse-code global_meaning_2.\n\n\nmil_data &lt;- mil_data %&gt;% \n  dplyr::mutate(\n    global_meaning_2 = 8 - global_meaning_2\n  )\n\n\nCreate composite scores for all of the subscale variables.\n\nThere are three subscales to calculate here for belonging, global_meaning, and mattering.\nAgain, you can type the item names into this command one by one. This does require careful checking to avoid duplicating or leaving out items, especially for subscales with many items. On the other hand, this method is likely to work better if you need specific and nonsequential items for each subscale (for instance, if the subscale is items 2, 3, 7, 10, and 12). For a &lt;tidyselect&gt; way to accompish this, have a look at the selection helper num_range() in the select() help documentation.\nInstead, if all the items with the same prefix belong to the same subscale (as they do here), c_across() + selection helpers are much preferred.\n\nmil_data &lt;- mil_data %&gt;% \n  dplyr::rowwise() %&gt;% \n  dplyr::mutate(\n    belonging_comp = mean(c_across(starts_with(\"belonging\")),\n                          na.rm = TRUE),\n    global_meaning_comp = mean(c_across(starts_with(\"global_meaning\")),\n                          na.rm = TRUE),\n    mattering_comp = mean(c_across(starts_with(\"mattering\")),\n                          na.rm = TRUE),\n  ) %&gt;% \n  dplyr::ungroup()"
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#well-done",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#well-done",
    "title": "Working with Qualtrics Data",
    "section": "Well done!",
    "text": "Well done!\nFrom here you can carry on with your data analysis: further cleaning, visualisation, and analysis. You’ve gained quite a few new skills today, so very well done indeed!"
  },
  {
    "objectID": "workshops/dissertations/qualtrics_workshop_sol.html#footnotes",
    "href": "workshops/dissertations/qualtrics_workshop_sol.html#footnotes",
    "title": "Working with Qualtrics Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor the purposes of simplicity, we’re going to pretend that Likert and similar rating scales are “continuous”.↩︎\nNote that this item is NOT reversed on the real scale; this is only for practice!↩︎\nNote that averaging Likert data is controversial (h/t Dr Vlad Costin!), but widespread in the literature. We’re going to press boldly onward anyway to not get too deep in the statistical weeds, but if you’re using Likert scales in your own research, it’s something you might want to consider.↩︎"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Under Construction\n\n\n\nThis section is still under construction. Check back for more in the future!\n\n\nThis section will be added to as necessary to support staff in their progress with R, for dissertation supervision and for the own work. See the sections in the sidebar for the documents currently available.\nIf you have a suggestion for a FAQ, guide, or other resource that would be helpful, you can drop it in the Suggestion Box on Canvas or get in touch."
  },
  {
    "objectID": "data_workbooks.html",
    "href": "data_workbooks.html",
    "title": "Data and Workbooks",
    "section": "",
    "text": "Download and save datasets to use for tutorial tasks here. Either copy the link to use in a reading-in function (e.g. readr::read_csv(), haven::read_sav()), or save the data at the link to a file to read in. Make sure that if you save the file, you keep the correct file suffix!\n\n\n\n\n\nFilename\n\n\nCitation/Source\n\n\nComments\n\n\nDownload\n\n\n\n\n\n\nanx_data.csv\n\n\nTerry, Lea, & Field (in prep)\n\n\nDataset shared for teaching purposes. Note that demographics in this dataset are SIMULATED FOR TEACHING PURPOSES and are NOT real data.\n\n\nDownload anx_data.csv\n\n\n\n\nanx_scores_data.csv\n\n\nTerry, Lea, & Field (in prep)\n\n\nDataset shared for teaching purposes, with mean subscale scores instead of individual items. Note that demographics in this dataset are SIMULATED FOR TEACHING PURPOSES and are NOT real data.\n\n\nDownload anx_scores_data.csv\n\n\n\n\nbp_data.csv\n\n\nSimon & Hurst (2021)\n\n\nDataset publicly available. Note that this subset of the public data has had ID variables and missing values randomly introduced for teaching purposes.\n\n\nDownload bp_data.csv\n\n\n\n\nmil_data.sav\n\n\nEldarwish et al., (in prep)\n\n\nDataset expected to be publicly available in the future. Note that this dataset is entirely simulated, based on existing real data.\n\n\nDownload mil_data.sav\n\n\n\n\nmil_data_wkshp.sav\n\n\nEldarwish et al., (in prep)\n\n\nVersion of mil_data.sav with additional simulated variables for workshop use, contributed by Dr Dan Evans\n\n\nDownload mil_data_wkshp.sav\n\n\n\n\nsyn_data.csv\n\n\nMealor et al., 2016\n\n\nDataset publicly available\n\n\nDownload syn_data.csv"
  },
  {
    "objectID": "data_workbooks.html#datasets",
    "href": "data_workbooks.html#datasets",
    "title": "Data and Workbooks",
    "section": "",
    "text": "Download and save datasets to use for tutorial tasks here. Either copy the link to use in a reading-in function (e.g. readr::read_csv(), haven::read_sav()), or save the data at the link to a file to read in. Make sure that if you save the file, you keep the correct file suffix!\n\n\n\n\n\nFilename\n\n\nCitation/Source\n\n\nComments\n\n\nDownload\n\n\n\n\n\n\nanx_data.csv\n\n\nTerry, Lea, & Field (in prep)\n\n\nDataset shared for teaching purposes. Note that demographics in this dataset are SIMULATED FOR TEACHING PURPOSES and are NOT real data.\n\n\nDownload anx_data.csv\n\n\n\n\nanx_scores_data.csv\n\n\nTerry, Lea, & Field (in prep)\n\n\nDataset shared for teaching purposes, with mean subscale scores instead of individual items. Note that demographics in this dataset are SIMULATED FOR TEACHING PURPOSES and are NOT real data.\n\n\nDownload anx_scores_data.csv\n\n\n\n\nbp_data.csv\n\n\nSimon & Hurst (2021)\n\n\nDataset publicly available. Note that this subset of the public data has had ID variables and missing values randomly introduced for teaching purposes.\n\n\nDownload bp_data.csv\n\n\n\n\nmil_data.sav\n\n\nEldarwish et al., (in prep)\n\n\nDataset expected to be publicly available in the future. Note that this dataset is entirely simulated, based on existing real data.\n\n\nDownload mil_data.sav\n\n\n\n\nmil_data_wkshp.sav\n\n\nEldarwish et al., (in prep)\n\n\nVersion of mil_data.sav with additional simulated variables for workshop use, contributed by Dr Dan Evans\n\n\nDownload mil_data_wkshp.sav\n\n\n\n\nsyn_data.csv\n\n\nMealor et al., 2016\n\n\nDataset publicly available\n\n\nDownload syn_data.csv"
  },
  {
    "objectID": "data_workbooks.html#workbooks",
    "href": "data_workbooks.html#workbooks",
    "title": "Data and Workbooks",
    "section": "Workbooks",
    "text": "Workbooks\nRight-click the link below and choose Save link as… to save as a .Qmd, or click through to view the text and copy/paste into an empty .Qmd document.\n\n\n\n\n\nTutorial/Workshop Name\n\n\nDownload\n\n\n\n\n\n\n01/02: IntRoduction\n\n\nDownload 01_02_intro_workbook.qmd\n\n\n\n\n03: Datasets\n\n\nDownload 03_datasets_workbook.qmd\n\n\n\n\n04: Reporting Linear Models with Quarto\n\n\nDownload 04_lm_workbook.qmd\n\n\n\n\n05: Filter and Select\n\n\nDownload 05_filter_workbook.qmd\n\n\n\n\n06: Mutate and Summarise\n\n\nDownload 06_changes_workbook.qmd\n\n\n\n\n07: Visualisations\n\n\nDownload 07_dataviz_workbook.qmd\n\n\n\n\n08: Analysis\n\n\nDownload 08_analysis_workbook.qmd\n\n\n\n\n09: Test Flight\n\n\nDownload 09_testflight_workbook.qmd\n\n\n\n\n10: Qualtrics and Labelled Data\n\n\nDownload 10_qtrics_workbook.qmd\n\n\n\n\nWorking with Qualtrics Data\n\n\nDownload qualtrics_workshop_workbook.qmd"
  }
]